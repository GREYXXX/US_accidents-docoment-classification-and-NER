{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837a7d22-716c-4325-9db8-64d19f3ca499",
   "metadata": {},
   "source": [
    "<b>Declaration</b>\n",
    "\n",
    "1. This is a project made by <b>@Author 22435044 XI RAO</b>\n",
    "2. All the \".pt\" file is our trained model, which helps to conduct comparative experiments \n",
    "3. All the classes for 3 tasks are encapsulated into the \"Models.py\".\n",
    "4. \"helper.py\" encapsulates some of the common-use functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddbe104b-d5c5-4074-8685-cabb9634791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f886372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00c8ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66cc1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71111408-0153-4733-b697-866c3b33c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da6172a7-6ca9-4dd2-b960-b01f9854f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0f185",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "945f1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('us_data_2000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf6445",
   "metadata": {},
   "source": [
    "### Data preparation for task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bf020",
   "metadata": {},
   "source": [
    "Task 1: transfer 'DEGREE_INJURY' to two classes of 'low_injury' and 'high_injury' for binary classification. The data have label of 'no value foun' were removed because we cannot know which classes they are.\n",
    "\n",
    "1. **low_injury**: The low injury class refers to injuries that are not serious. The names and ID of the injury in this class are shown below, which has total 861 numbers in all dataset and 680 numbers in training data. \n",
    "<br>NO DYS AWY FRM WRK,NO RSTR ACT(6) ; INJURIES INVOLVNG NONEMPLOYEES(9); ACCIDENT ONLY(0); OCCUPATNAL ILLNESS NOT DEG 1-6(7); ALL OTHER CASES (INCL 1ST AID)(10); INJURIES DUE TO NATURAL CAUSES(8)\n",
    "\n",
    "\n",
    "\n",
    "2. **high_injury**: The high injury class refers to injuries that are serious. The names and ID of the injury in this class are shown below, which has total 1128 numbers in all dataset and 991 numbers in training data.\n",
    "<br>DAYS AWAY FROM WORK ONLY(3); DYS AWY FRM WRK & RESTRCTD ACT(4); PERM TOT OR PERM PRTL DISABLTY(2); FATALITY(1); \n",
    "DAYS RESTRICTED ACTIVITY ONLY(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "771bfe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only relevant fiels for task 1\n",
    "df_task1 = df[[\"DEGREE_INJURY\", \"DEGREE_INJURY_CD\", 'NARRATIVE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc9c4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'no_value_found' freature in 'DEGREE_INJURY'\n",
    "df_task1 = df_task1[df_task1['DEGREE_INJURY_CD'] != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b148cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1989, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27122908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: transfer 'DEGREE_INJURY' to Binary labels\n",
    "x = df_task1[['DEGREE_INJURY_CD']].replace(['3', '4', '2', '1', '5'], 'high_injury')\n",
    "df_task1['binary_injury'] = x.replace(['6','9','0','7','10','8'], 'low_injury')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa0fe9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>binary_injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>Employee was cleaning up at the Primary Crushe...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO DYS AWY FRM WRK,NO RSTR ACT</td>\n",
       "      <td>6</td>\n",
       "      <td>Handle of sledgehammer broke and head of hamme...</td>\n",
       "      <td>low_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>3</td>\n",
       "      <td>EMPLOYEE WAS CLIMBING DOWN A LADDER AND WHEN H...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>HE PULLED A BACK MUSCLE WHILE STACKING BAGS OF...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>EE hands began to break out in a rash after he...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DEGREE_INJURY DEGREE_INJURY_CD  \\\n",
       "0   DAYS RESTRICTED ACTIVITY ONLY                5   \n",
       "1  NO DYS AWY FRM WRK,NO RSTR ACT                6   \n",
       "2        DAYS AWAY FROM WORK ONLY                3   \n",
       "3   DAYS RESTRICTED ACTIVITY ONLY                5   \n",
       "4   DAYS RESTRICTED ACTIVITY ONLY                5   \n",
       "\n",
       "                                           NARRATIVE binary_injury  \n",
       "0  Employee was cleaning up at the Primary Crushe...   high_injury  \n",
       "1  Handle of sledgehammer broke and head of hamme...    low_injury  \n",
       "2  EMPLOYEE WAS CLIMBING DOWN A LADDER AND WHEN H...   high_injury  \n",
       "3  HE PULLED A BACK MUSCLE WHILE STACKING BAGS OF...   high_injury  \n",
       "4  EE hands began to break out in a rash after he...   high_injury  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adf46d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_injury    1128\n",
       "low_injury      861\n",
       "Name: binary_injury, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task1[\"binary_injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cec99dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_task1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a73cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c890707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_injury    911\n",
       "low_injury     680\n",
       "Name: binary_injury, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"binary_injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c7f28e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>binary_injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>3</td>\n",
       "      <td>EE WAS REBUILDING HAUL ROAD BERM WITH LOADER W...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>Employee was re-positioning a jack leg drill d...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>ALL OTHER CASES (INCL 1ST AID)</td>\n",
       "      <td>10</td>\n",
       "      <td>Employee has a pre-existing heart condition.  ...</td>\n",
       "      <td>low_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>3</td>\n",
       "      <td>PIECE OF DRAWROCK FELL FROM BETWEEN BOLTS STRI...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>Employee stated he experienced back discomfort...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>5</td>\n",
       "      <td>Supervisor was walking from the map case back ...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>3</td>\n",
       "      <td>Employee was cleaning coal with a small loader...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>3</td>\n",
       "      <td>Operator was tramming bolter and fell down, pu...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>NO DYS AWY FRM WRK,NO RSTR ACT</td>\n",
       "      <td>6</td>\n",
       "      <td>Thumb smashed while trying to punch holes in b...</td>\n",
       "      <td>low_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>3</td>\n",
       "      <td>HE WAS CHECKING SUMP PUMP , WHEN HE RAN INTO I...</td>\n",
       "      <td>high_injury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1591 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DEGREE_INJURY DEGREE_INJURY_CD  \\\n",
       "160         DAYS AWAY FROM WORK ONLY                3   \n",
       "1601   DAYS RESTRICTED ACTIVITY ONLY                5   \n",
       "320   ALL OTHER CASES (INCL 1ST AID)               10   \n",
       "998         DAYS AWAY FROM WORK ONLY                3   \n",
       "469    DAYS RESTRICTED ACTIVITY ONLY                5   \n",
       "...                              ...              ...   \n",
       "840    DAYS RESTRICTED ACTIVITY ONLY                5   \n",
       "1223        DAYS AWAY FROM WORK ONLY                3   \n",
       "1661        DAYS AWAY FROM WORK ONLY                3   \n",
       "563   NO DYS AWY FRM WRK,NO RSTR ACT                6   \n",
       "688         DAYS AWAY FROM WORK ONLY                3   \n",
       "\n",
       "                                              NARRATIVE binary_injury  \n",
       "160   EE WAS REBUILDING HAUL ROAD BERM WITH LOADER W...   high_injury  \n",
       "1601  Employee was re-positioning a jack leg drill d...   high_injury  \n",
       "320   Employee has a pre-existing heart condition.  ...    low_injury  \n",
       "998   PIECE OF DRAWROCK FELL FROM BETWEEN BOLTS STRI...   high_injury  \n",
       "469   Employee stated he experienced back discomfort...   high_injury  \n",
       "...                                                 ...           ...  \n",
       "840   Supervisor was walking from the map case back ...   high_injury  \n",
       "1223  Employee was cleaning coal with a small loader...   high_injury  \n",
       "1661  Operator was tramming bolter and fell down, pu...   high_injury  \n",
       "563   Thumb smashed while trying to punch holes in b...    low_injury  \n",
       "688   HE WAS CHECKING SUMP PUMP , WHEN HE RAN INTO I...   high_injury  \n",
       "\n",
       "[1591 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c15c13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset for train binary classification\n",
    "train_df = [train[\"binary_injury\"],train[\"NARRATIVE\"]]\n",
    "headers = [\"binary_injury\", \"NARRATIVE\"]\n",
    "Binary_df = pd.concat(train_df, axis=1, keys=headers)\n",
    "\n",
    "# create new dataset for test binary classification\n",
    "test_df = [test[\"binary_injury\"],test[\"NARRATIVE\"]]\n",
    "headers = [\"binary_injury\", \"NARRATIVE\"]\n",
    "test_injury = pd.concat(test_df, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e8274e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high_injury', 'low_injury'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_injury[['binary_injury']].describe()\n",
    "# Unique classes\n",
    "set(test_injury.binary_injury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c8a1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training dataset\n",
    "by_injury = collections.defaultdict(list)\n",
    "for _, row in Binary_df.iterrows():\n",
    "    by_injury[row.binary_injury].append(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "309fbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split data by 0.7 for training and 0.3 validation\n",
    "final_list = []\n",
    "np.random.seed(1337)\n",
    "\n",
    "for _, item_list in sorted(by_injury.items()):\n",
    "\n",
    "    np.random.shuffle(item_list)\n",
    "    \n",
    "    n_total = len(item_list)\n",
    "    n_train = round(0.7 * n_total)  #--->638; 476\n",
    "    n_val = round(0.3 * n_total)    #---->273; 204\n",
    "    \n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    \n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66bd2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add text data\n",
    "for _, row in test_injury.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    row_dict['split'] = 'test'\n",
    "    final_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf2034f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    1114\n",
       "val       477\n",
       "test      398\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final dataset with train, test and validation data\n",
    "final1 = pd.DataFrame(final_list)\n",
    "final1.split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5efbf3",
   "metadata": {},
   "source": [
    "### Data preparation for task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533ae59",
   "metadata": {},
   "source": [
    "Task 2: Divide 'INJ_BODY_PART' to three classes by diffrent injury part of body, which are head&toe, extremities and trunk&mutipart. The data have label of 'NO VALUE FOUND' and 'UNCLASSIFIED' were removed because we cannot know which classes they are.\n",
    "\n",
    "1. **head&toe**: The names and ID of the injury head&toe are shown below, which has total 597 numbers in all dataset and 481 numbers in training data.\n",
    "EYE(S) OPTIC NERVE/VISON（130); HEAD,NEC(100); MOUTH/LIP/TEETH/TONGUE/THROAT/TASTE(142); EAR(S) INTERNAL &\n",
    "HEARING(122); FACE,NEC(140）; JAW INCLUDE CHIN(311）; NOSE/NASAL PASSAGES/SINUS/SMELL(550）; BRAIN(110）; EAR(S) EXTERNAL(514）; SCALP(170）; FACE, MULTIPLE PARTS(314）; EAR(S) INTERNAL & EXTERNAL(120）; HEAD, MULTIPLE PARTS(144）; SKULL(160）; NECK(200）; TOE(S)/PHALANGES(540）; FINGER(S)/THUMB(340）   \n",
    "\n",
    "\n",
    "2. **extremities**: The names and ID of the injury extremities are shown below, which has total 593 numbers in all dataset and 470 numbers in training data.\n",
    "KNEE/PATELLA(512）; ANKLE(520）; HAND (NOT WRIST OR FINGERS)(330）; WRIST(320）; FOOT(NOT ANKLE/TOE)/TARSUS/METATARSUS(530）; ARM,NEC(310）; LOWER LEG/TIBIA/FIBULA(513）; FOREARM/ULNAR/RADIUS(313）; ELBOW(312）; LEG, NEC(510）; THIGH/FEMUR(511）; UPPER ARM/HUMERUS(141）; ARM, MULTIPLE PARTS(150）; LEG, MULTIPLE; PARTS(121）; LOWER EXTREMITIES, MULTIPLE PARTS(143）; UPPER EXTREMITIES, MULTIPLE(350）\n",
    "\n",
    "3. **trunk&mutipart**: The names and ID of the injury extremities are shown below, which has total 566 numbers in all dataset and 453 numbers in training data.\n",
    "ABDOMEN/INTERNAL ORGANS(410）; CHEST (RIBS/BREAST BONE/CHEST ORGNS)(430）; BACK (MUSCLES/SPINE/S-CORD/TAILBONE)(420）; SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)(450）; HIPS (PELVIS/ORGANS/KIDNEYS/BUTTOCKS)(440）; TRUNK,NEC(400）; BODY SYSTEMS(600）; BODY PARTS, NEC(800); TRUNK, MULTIPLE PARTS(460）; MULTIPLE PARTS (MORE THAN ONE MAJOR)(700）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db900885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task2 = df[['INJ_BODY_PART', 'INJ_BODY_PART_CD', 'NARRATIVE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4927229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'no_value_found'&'UNCLASSIFIED' freature in 'INJ_BODY_PART_CD'\n",
    "df_task2 = df_task2[(df_task2['INJ_BODY_PART_CD'] != '?') & (df_task2['INJ_BODY_PART_CD']!='900')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "487784bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1756, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61a42336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: transfer 'INJ_BODY_PART' to mutiple classes\n",
    "y = df_task2[['INJ_BODY_PART_CD']].replace(['410', '430', '420', '450', '440', '400', '600', '800','460','700'], 'trunk&mutipart')\n",
    "y = y.replace(['512', '520', '330', '320', '530', '310', '513', '313', '312','510','511', '141', '150', '121','143','350'], 'extremities')\n",
    "y = y.replace(['130', '100', '142', '122', '140', '311', '550', '110', '514', '170','314','120','144','160', '200','540','340'], 'head&toe')\n",
    "\n",
    "df_task2['body_injury'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d878d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "head&toe          597\n",
       "extremities       593\n",
       "trunk&mutipart    566\n",
       "Name: body_injury, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task2[\"body_injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22b2b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "train2, test2 = train_test_split(df_task2, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e8a5dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test2.shape    #352\n",
    "train2.shape       # 1404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c805d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extremities       481\n",
       "head&toe          470\n",
       "trunk&mutipart    453\n",
       "Name: body_injury, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[\"body_injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e30becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset for train mutiple classification\n",
    "train2_df = [train2[\"body_injury\"],train2[\"NARRATIVE\"]]\n",
    "headers = [\"body_injury\", \"NARRATIVE\"]\n",
    "Mutiple_df = pd.concat(train2_df, axis=1, keys=headers)\n",
    "\n",
    "# create new dataset for test mutiple classification\n",
    "test2_df = [test2[\"body_injury\"],test2[\"NARRATIVE\"]]\n",
    "headers = [\"body_injury\", \"NARRATIVE\"]\n",
    "test_df = pd.concat(test2_df, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f9f6e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extremities', 'head&toe', 'trunk&mutipart'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['body_injury']].describe()\n",
    "# Unique classes\n",
    "set(test_df.body_injury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceafbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training dataset\n",
    "by_body_injury = collections.defaultdict(list)\n",
    "for _, row in Mutiple_df.iterrows():\n",
    "    by_body_injury[row.body_injury].append(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b8f15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split data by 0.7 for training and 0.3 validation\n",
    "final_list2 = []\n",
    "np.random.seed(1337)\n",
    "\n",
    "for _, item_list in sorted(by_body_injury.items()):\n",
    "\n",
    "    np.random.shuffle(item_list)\n",
    "    \n",
    "    n_total = len(item_list)\n",
    "    n_train = round(0.7 * n_total)  #--->638; 476\n",
    "    n_val = round(0.3 * n_total)    #---->273; 204\n",
    "    \n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    \n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "\n",
    "    # Add to final list\n",
    "    final_list2.extend(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72b310c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add test data\n",
    "for _, row in test_df.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    row_dict['split'] = 'test'\n",
    "    final_list2.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7320feb1-413c-4031-88ff-b108e3f2c577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    983\n",
       "val      421\n",
       "test     352\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final dataset with train, test and validation data\n",
    "final2 = pd.DataFrame(final_list2)\n",
    "final2.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e416d7a-749c-4cd5-a2a2-72abbf410b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extremities</td>\n",
       "      <td>sand covered rock that employee stepped on</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extremities</td>\n",
       "      <td>PIECE OF ROCK FELL ON LEG WHILE SPLITTING ROCK...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extremities</td>\n",
       "      <td>Employee stepped off bolter, placed foot on un...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extremities</td>\n",
       "      <td>EE WAS USING A RATCHET TO TIGHTEN A BOLT AND R...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extremities</td>\n",
       "      <td>While tightening conveyor chain on buggy, ee p...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>extremities</td>\n",
       "      <td>Employee was starting a 2\" gasoline powered wa...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>extremities</td>\n",
       "      <td>While moving a miner out of a crosscut, he ste...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>trunk&amp;mutipart</td>\n",
       "      <td>EMPLOYEE WAS OPERATING DOUBLE HEAD FLETCHER ON...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>extremities</td>\n",
       "      <td>THE EE WAS IN THE PROCESS OF ASSEMBLING A CHUT...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>trunk&amp;mutipart</td>\n",
       "      <td>Bolting outer bolt, completed,raised stab jack...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1756 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         body_injury                                          NARRATIVE  split\n",
       "0        extremities         sand covered rock that employee stepped on  train\n",
       "1        extremities  PIECE OF ROCK FELL ON LEG WHILE SPLITTING ROCK...  train\n",
       "2        extremities  Employee stepped off bolter, placed foot on un...  train\n",
       "3        extremities  EE WAS USING A RATCHET TO TIGHTEN A BOLT AND R...  train\n",
       "4        extremities  While tightening conveyor chain on buggy, ee p...  train\n",
       "...              ...                                                ...    ...\n",
       "1751     extremities  Employee was starting a 2\" gasoline powered wa...   test\n",
       "1752     extremities  While moving a miner out of a crosscut, he ste...   test\n",
       "1753  trunk&mutipart  EMPLOYEE WAS OPERATING DOUBLE HEAD FLETCHER ON...   test\n",
       "1754     extremities  THE EE WAS IN THE PROCESS OF ASSEMBLING A CHUT...   test\n",
       "1755  trunk&mutipart  Bolting outer bolt, completed,raised stab jack...   test\n",
       "\n",
       "[1756 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293aa1f",
   "metadata": {},
   "source": [
    "### Visualise to show the class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ef214ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise to show the class balance for Task1 \n",
    "train_data = final1[final1[\"split\"] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd83b6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_injury    638\n",
       "low_injury     476\n",
       "Name: binary_injury, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.binary_injury.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6a1f80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.02, 'Task1 Class Balance')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_data.binary_injury.value_counts().plot(kind = 'barh')\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "train_data['binary_injury'].value_counts().plot(kind='barh', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Binary labels\", labelpad=14)\n",
    "plt.ylabel(\"Count of labels\", labelpad=14)\n",
    "plt.title(\"Task1 Class Balance\", y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a70af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = final2[final2[\"split\"] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac02a691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "train_data2['body_injury'].value_counts().plot(kind='barh', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Mutiple labels\", labelpad=14)\n",
    "plt.ylabel(\"Count of labels\", labelpad=14)\n",
    "plt.title(\"Task2 Class Balance\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1ba61da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.02, 'Task1 Class Balance')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAIoCAYAAADujAgsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABD90lEQVR4nO3de1yUZf7/8fdw1EpTiUkj1zWzaLENs0wywQ4CiqShFWpotZrtKm1lmAJ5KDxktOaxo1urWUp4gAzRSrPMU/LbMlozM7E8xEHzgAYIc//+8OskKsaVjJxez8fDx2Pmmmvu+zP3zFy8ve6579tmWZYlAACASnKr7gIAAEDtQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYMSjugsAAFROUlKSvvjiC0nSjh075OfnpwYNGkiSFi5c6LxdGTExMRowYIDCw8PP+vi3336rwYMHa+3atRUuY8eOHXrppZeUk5Mjm82mxo0b6/HHH9dNN92k3bt3KzIyUv/9738NXqGZxYsXa8KECbryyitlWZZKS0vVsmVLPffcc7Lb7ed87h133KFp06bp+uuvd1l9dRnhAQBqicTEROftO+64Q8nJyVX+x6+0tFRvv/22Xn/9dR07dqzCfj/88IMGDRqkSZMmqUuXLpKk9evX69FHH9W7776rhg0bVmldFbnpppv06quvOu+PGzdO06dPV1JS0gVZf31FeACAWu7YsWMaN26cdu3apYMHD+riiy9WcnKyrrrqKq1cuVIvv/yybDab3N3dNXLkSN18883O55aWlmrEiBHy8PDQ888/r//973/atm2bZs6cqYcffrjCdb7++uvq06ePMzhIUlBQkF588cUzZkAKCgo0ZswY7d+/X/n5+fLz89NLL70kHx8fvfPOO1qwYIE8PT3l7e2tZ599VldffXWF7edy/PhxFRYWqmXLlr+73pMcDocmTpyor776SkePHpVlWUpKSlKHDh00atQoXXLJJdq2bZt+/vlnXXvttXr++ed18cUX66uvvlJSUpJ+/fVXeXp6auTIkQoKCtKOHTs0YcIEHTx4UGVlZYqJiVHfvn2N3s9awQIA1Dq33367tWXLFsuyLGv58uXWc88953zsmWeesZ599lnLsizrzjvvtP773/9almVZn332mTVjxgzLsizrgQcesNLT061//OMf1vjx4y2Hw1Fu+T/99JMVGBhY4fp79uxpffLJJxU+furz33rrLevVV1+1LMuyHA6HNXjwYGvOnDlWaWmpFRAQYOXm5lqWZVlLliyxFixYUGH76RYtWmTdeOON1t13321FRkZaHTt2tLp06WLt3r37nOs9dfv9v//3/6zY2FirrKzMsizLevXVV62hQ4dalmVZTz/9tHX//fdbxcXFVklJidW7d28rNTXVKikpsTp37mytXr3asizL+vrrr62ePXtaxcXFVo8ePazs7GzLsizr8OHDVvfu3Z3bvy5h5gEAarnw8HC1bNlS8+bN065du7Rp0ya1b99ekhQREaHhw4crJCREnTt31pAhQ5zPe/7553X06FF9+OGHstlsRuu02WxyOByV6jto0CBt3rxZb775pnJycrR9+3bdcMMNcnd3V3h4uKKjo9W1a1fddtttCgkJqbD9bE7dbeFwOPTyyy9r8ODBysjIqHC9p2rfvr0uvfRSLViwQD/99JM2btyoiy++2Pl4ly5d5OXlJUm65pprdOjQIX333Xdyc3NT165dJUnt2rXT+++/r++//14//vij4uPjnc8vKirS//73PwUGBlZ209YKHG0BALXcO++8o4SEBDVo0ECRkZHq2bOnrP+7bNETTzyhd955R+3atdPixYs1YMAA5/PuvvtuRUdHl/stRWUFBgbqyy+/PKN95syZSk9PL9f2wgsvaNq0aWratKnuv/9+de7c2VlfcnKyXnnlFf3pT3/Sa6+9pieffPKc7efi5uammJgY/fDDD9q/f/8513vSJ598oqFDh0qS7rzzTvXr16/c46fugrHZbLIsS+7u7meEre+++05lZWVq1KiR0tLSnP9SUlLUp0+f3629tiE8AEAtt3btWt1zzz2699571bp1a61atUplZWUqLS3VHXfcoV9//VX9+vXT2LFjtW3bNpWUlEiS/vrXv+rxxx/Xjz/+qJSUFKN1/u1vf9N7771X7miMTz/9VPPmzZO/v/8Z9Q0aNEi9e/eWj4+P1q1bp7KyMh04cEAhISFq0qSJHnzwQT3++OP6+uuvK2yvjE8++UR+fn5q1qxZhes91eeff67bb79d/fv3V7t27fTRRx+d0ed0V111lWw2mz7//HNJ0jfffKNBgwapdevWatCggdLS0iRJ+/btU8+ePZWdnV2p2msTdlsAQC338MMPa8yYMUpNTZV0Ylbgu+++k4eHh+Lj4/XUU0/Jw8NDNptNEydOdE7DS5K3t7cmT56shx9+WJ06ddKf/vSnSq2zVatWeuWVV/TSSy/p+eefl8PhULNmzfTyyy/rmmuu0e7du519hw0bpilTpmjatGny9PTUjTfeqB9//FHNmjXT3//+dz344INq0KCB3N3dlZSUVGH72WzevFm9evWSzWZTaWmpmjRpolmzZsnNza3C9Z4qOjpaI0aMUGRkpEpLS9W5c2etXLnynLtkvLy8NGPGDE2cOFFTpkyRp6enZsyYIS8vL82ePVsTJkzQG2+8odLSUv3zn/9Uhw4dKrVNaxObdfocDgAAwDmw2wIAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMCIhysXPm3aNK1YsUI2m019+/bVQw89pNGjRysrK0sNGzaUJA0fPlzdunXT1q1blZCQoKNHj+qmm27S+PHj5eFR+fJ++eWoHA7LVS8FqNXc3Gxq2vTi6i6jxmHcACp2rnHDZeFh06ZN2rBhg9LT01VaWqoePXooJCRE2dnZevvtt2W328v1j4uLU1JSkgIDAxUfH6+UlBT179+/0utzOCwGAQBGGDeAP8Zluy06duyouXPnysPDQ/v371dZWZkaNGigvXv3Kj4+XpGRkZo+fbocDof27NmjoqIiBQYGSpKioqKUmZnpqtIAAMB5cOlvHjw9PTV9+nRFREQoKChIpaWl6tSpkyZOnKiUlBRt3rxZqampysvLk6+vr/N5vr6+ys3NdWVpAADgD3Lpbx4k6bHHHtOQIUP06KOPav369Zo1a5bzsZiYGC1dulRt2rSRzWZztluWVe5+Zfj4XFJlNQMAgIq5LDzs2LFDJSUluu6669SwYUOFhoYqIyNDTZo0UVhYmKQTIcHDw0PNmzdXfn6+87kFBQVn/Cbi9+zfX8i+S6ACbm42AjaAKuOy3Ra7d+9WYmKiSkpKVFJSoo8//lg333yzJk6cqEOHDun48eNauHChunXrJj8/P3l7eysrK0uSlJaWpuDgYFeVBgAAzoPLZh5CQkK0ZcsW9e7dW+7u7goNDdXw4cPVtGlT9evXT6WlpQoNDVXPnj0lScnJyUpMTFRhYaECAgI0cOBAV5UGAADOg82yrDox189uC6Bi7LY4O8YNoGLnGjc4wyQAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAIy67JHdN0ahxAzXw9qzuMqpcUfFxHTlcVN1lAHVeXR1DLiTGq7qnzoeHBt6e6j9yfnWXUeXemTJAR8SXEXC1ujqGXEiMV3UPuy0AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACM1PmTROE3TS/1koeXd3WXUeVKS4r1y6GS6i4DAOoNwkM94uHlrawpg6u7jCrXYeQbkggPAHChsNsCAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8ACgRlm1apWioqLUvXt3JSUlSZLWrVunyMhIhYaGaurUqc6+W7duVVRUlMLCwpSQkKDS0tLqKhuoVwgPAGqMn376SWPHjtXs2bOVnp6u//3vf1qzZo3i4+M1e/ZsZWRkKDs7W2vWrJEkxcXFacyYMVqxYoUsy1JKSko1vwKgfiA8AKgxPvzwQ/Xo0UPNmzeXp6enpk6dqoYNG6pVq1Zq2bKlPDw8FBkZqczMTO3Zs0dFRUUKDAyUJEVFRSkzM7N6XwBQT3BJbgA1xq5du+Tp6alHH31U+/btU9euXdW2bVv5+vo6+9jtduXm5iovL69cu6+vr3Jzc6ujbKDeITygXmp8qbe8vbyqu4wqV1xSosOHiqu7jD+srKxMmzdv1rx583TRRRfp73//uxo0aCCbzebsY1mWbDabHA7HWdtN+PhcUmW149x8fRtVdwmoQoQH1EveXl568M1/VncZVe6th6ZJqr3h4bLLLlNQUJCaNWsmSbrrrruUmZkpd3d3Z5/8/HzZ7XY1b95c+fn5zvaCggLZ7Xaj9e3fXyiHwzpnH/7oVY38/CPVXQIMubnZKgzY/OYBQI1x++23a+3atTp8+LDKysr02WefKTw8XDt37tSuXbtUVlamZcuWKTg4WH5+fvL29lZWVpYkKS0tTcHBwdX8CoD6gZkHADXGDTfcoMGDB6t///46fvy4OnfurH79+umqq65SbGysiouLFRISovDwcElScnKyEhMTVVhYqICAAA0cOLCaXwFQPxAeANQoffv2Vd++fcu1BQUFKT09/Yy+/v7+Sk1NvVClAfg/7LYAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjLg0PEybNk09evRQRESE3nzzTUnSunXrFBkZqdDQUE2dOtXZd+vWrYqKilJYWJgSEhJUWlrqytIAAMAf5LLwsGnTJm3YsEHp6elatGiR5s2bp2+//Vbx8fGaPXu2MjIylJ2drTVr1kiS4uLiNGbMGK1YsUKWZSklJcVVpQEAgPPgsvDQsWNHzZ07Vx4eHtq/f7/Kysp0+PBhtWrVSi1btpSHh4ciIyOVmZmpPXv2qKioSIGBgZKkqKgoZWZmuqo0AABwHly628LT01PTp09XRESEgoKClJeXJ19fX+fjdrtdubm5Z7T7+voqNzfXlaUBAIA/yMPVK3jsscc0ZMgQPfroo8rJyZHNZnM+ZlmWbDabHA7HWdtN+PhcUmU11xa+vo2qu4Qag23xG7YFAFdzWXjYsWOHSkpKdN1116lhw4YKDQ1VZmam3N3dnX3y8/Nlt9vVvHlz5efnO9sLCgpkt9uN1rd/f6EcDuuM9ro8kObnHzHqz7b4TX3bFm5utnoZsAG4hst2W+zevVuJiYkqKSlRSUmJPv74Y0VHR2vnzp3atWuXysrKtGzZMgUHB8vPz0/e3t7KysqSJKWlpSk4ONhVpQEAgPPgspmHkJAQbdmyRb1795a7u7tCQ0MVERGhZs2aKTY2VsXFxQoJCVF4eLgkKTk5WYmJiSosLFRAQIAGDhzoqtIAAMB5cOlvHmJjYxUbG1uuLSgoSOnp6Wf09ff3V2pqqivLAQAAVYAzTAIAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABjxqO4CAOBUMTExOnDggDw8TgxPzz77rI4ePapJkyapuLhY3bt31xNPPCFJ2rp1qxISEnT06FHddNNNGj9+vPN5AFyHbxmAGsOyLOXk5Gj16tXOEFBUVKTw8HDNmzdPLVq00NChQ7VmzRqFhIQoLi5OSUlJCgwMVHx8vFJSUtS/f/9qfhVA3cduCwA1xg8//CBJevjhh3X33Xfr7bff1pYtW9SqVSu1bNlSHh4eioyMVGZmpvbs2aOioiIFBgZKkqKiopSZmVmN1QP1B+EBQI1x+PBhBQUFadasWXrrrbe0YMEC7d27V76+vs4+drtdubm5ysvLK9fu6+ur3Nzc6igbqHfYbQGgxmjfvr3at2/vvN+3b19Nnz5dHTp0cLZZliWbzSaHwyGbzXZGuwkfn0vOv2hUiq9vo+ouAVWI8ACgxti8ebOOHz+uoKAgSScCgZ+fn/Lz85198vPzZbfb1bx583LtBQUFstvtRuvbv79QDod1zj780asa+flHqrsEGHJzs1UYsNltAaDGOHLkiKZMmaLi4mIVFhZqyZIlevLJJ7Vz507t2rVLZWVlWrZsmYKDg+Xn5ydvb29lZWVJktLS0hQcHFzNrwCoH5h5AFBj3H777frqq6/Uu3dvORwO9e/fX+3bt9fkyZMVGxur4uJihYSEKDw8XJKUnJysxMREFRYWKiAgQAMHDqzmVwDUD4QHADXK448/rscff7xcW1BQkNLT08/o6+/vr9TU1AtUGYCT2G0BAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARl56eeubMmVq+fLkkKSQkRCNHjtTo0aOVlZWlhg0bSpKGDx+ubt26aevWrUpISNDRo0d10003afz48fLw4OzZAADUNC7767xu3TqtXbtWS5Yskc1m0+DBg/Xhhx8qOztbb7/99hmXzo2Li1NSUpICAwMVHx+vlJQU9e/f31XlAQCAP8hl4cHX11ejRo2Sl5eXJKlNmzbau3ev9u7dq/j4eOXm5qpbt24aPny49u3bp6KiIgUGBkqSoqKiNH36dMIDAOAMTS/1koeXd3WXUWuVlhTrl0Ml57UMl4WHtm3bOm/n5ORo+fLlmj9/vjZt2qSxY8eqUaNGGjp0qFJTU9W2bVv5+vo6+/v6+io3N9dVpQEAajEPL29lTRlc3WXUWh1GviGphoaHk7Zv366hQ4dq5MiRuuqqqzRr1iznYzExMVq6dKnatGkjm83mbLcsq9z9yvDxuaTKaq4tfH0bVXcJNQbb4jdsCwCu5tLwkJWVpccee0zx8fGKiIjQtm3blJOTo7CwMEknQoKHh4eaN2+u/Px85/MKCgrO+E3E79m/v1AOh3VGe10eSPPzjxj1Z1v8pr5tCzc3W70M2ABcw2WHau7bt0/Dhg1TcnKyIiIiJJ0ICxMnTtShQ4d0/PhxLVy4UN26dZOfn5+8vb2VlZUlSUpLS1NwcLCrSgMAAOfBZTMPc+bMUXFxsSZPnuxsi46O1iOPPKJ+/fqptLRUoaGh6tmzpyQpOTlZiYmJKiwsVEBAgAYOHOiq0gAAwHlwWXhITExUYmLiWR8bMGDAGW3+/v5KTU11VTkAAKCKcIZJAABghPAAAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARwgMAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABghPAAAACMEB4AAIARwgOAGuf555/XqFGjJEnr1q1TZGSkQkNDNXXqVGefrVu3KioqSmFhYUpISFBpaWl1lQvUO4QHADXK+vXrtWTJEklSUVGR4uPjNXv2bGVkZCg7O1tr1qyRJMXFxWnMmDFasWKFLMtSSkpKdZYN1CuEBwA1xsGDBzV16lQ9+uijkqQtW7aoVatWatmypTw8PBQZGanMzEzt2bNHRUVFCgwMlCRFRUUpMzOzGisH6hfCA4AaY8yYMXriiSfUuHFjSVJeXp58fX2dj9vtduXm5p7R7uvrq9zc3AteL1BfeVR3AQAgSe+9955atGihoKAgLV68WJLkcDhks9mcfSzLks1mq7DdlI/PJedfOCrF17dRdZeAU5zv+0F4AFAjZGRkKD8/X7169dKhQ4d07Ngx7dmzR+7u7s4++fn5stvtat68ufLz853tBQUFstvtxuvcv79QDod1zj780asa+flHqmxZvCfnrzLvh5ubrcKATXgAUCO8+eabztuLFy/Wpk2bNH78eIWGhmrXrl268sortWzZMvXp00d+fn7y9vZWVlaWOnTooLS0NAUHB1dj9UD9QngAUGN5e3tr8uTJio2NVXFxsUJCQhQeHi5JSk5OVmJiogoLCxUQEKCBAwdWc7VA/UF4AFDjREVFKSoqSpIUFBSk9PT0M/r4+/srNTX1QpcGQBxtAQAADBEeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACMuDQ8zZ85URESEIiIiNGXKFEnSunXrFBkZqdDQUE2dOtXZd+vWrYqKilJYWJgSEhJUWlrqytIAAMAf5LLwsG7dOq1du1ZLlizR0qVL9c0332jZsmWKj4/X7NmzlZGRoezsbK1Zs0aSFBcXpzFjxmjFihWyLEspKSmuKg0AAJwHl4UHX19fjRo1Sl5eXvL09FSbNm2Uk5OjVq1aqWXLlvLw8FBkZKQyMzO1Z88eFRUVKTAwUNKJs8tlZma6qjQAAHAeXBYe2rZt6wwDOTk5Wr58uWw2m3x9fZ197Ha7cnNzlZeXV67d19dXubm5rioNAACcB5df22L79u0aOnSoRo4cKXd3d+Xk5DgfsyxLNptNDodDNpvtjHYTFV02tC7jsrS/YVv8hm0BwNVcGh6ysrL02GOPKT4+XhEREdq0aZPy8/Odj+fn58tut6t58+bl2gsKCmS3243WtX9/oRwO64z2ujyQVuZ67KdiW/ymvm0LNzdbvQzYAFzDZbst9u3bp2HDhik5OVkRERGSpBtuuEE7d+7Url27VFZWpmXLlik4OFh+fn7y9vZWVlaWJCktLU3BwcGuKg0AAJwHl808zJkzR8XFxZo8ebKzLTo6WpMnT1ZsbKyKi4sVEhKi8PBwSVJycrISExNVWFiogIAADRw40FWlAQCA8+Cy8JCYmKjExMSzPpaenn5Gm7+/v1JTU11VDgAAqCKcYRIAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAkUqFh9zc3DPavv/++yovBkDdwbgB1F3nDA8HDx7UwYMHNWTIEB06dMh5v6CgQMOHD79QNQKoRRg3gLrP41wPjhgxQp9//rkk6ZZbbvntSR4eCgsLc21lAGolxg2g7jtneJgzZ44kafTo0Zo0adIFKQhA7ca4AdR95wwPJ02aNEl79uzRoUOHZFmWsz0gIMBlhQGo3Rg3gLqrUuFh+vTpmjNnjnx8fJxtNptNH3/8scsKA1C7MW4AdVelwsPSpUu1cuVKXX755a6uB0AdwbgB1F2VOlSzRYsWDAAAjDBuAHVXpWYegoKCNGXKFN15551q0KCBs519lwAqwrgB1F2VCg+LFy+WJGVmZjrb2HcJ4FwYN4C6q1LhYdWqVa6uA0Adw7gB1F2VCg9vvvnmWdsfeuihKi0GQN3BuAHUXZUKD999953zdklJib744gsFBQW5rCgAtR/jBlB3VfokUafKzc1VQkKCSwoCUDcwbgB11x+6JPfll1+uPXv2VHUtAOowxg2g7jD+zYNlWcrOzi531jgAOB3jBlB3Gf/mQTpx8peRI0e6pCAAdQPjBlB3Gf3mYc+ePSotLVWrVq1cWhSA2o9xA6i7KhUedu3apX/84x/Ky8uTw+FQ06ZN9eqrr6pNmzaurg9ALcW4AdRdlfrB5LPPPqvBgwfriy++UFZWlv7+979r/Pjxrq4NQC3GuAHUXZUKD/v379c999zjvN+nTx/98ssvLisKQO3HuAHUXZUKD2VlZTp48KDz/oEDB1xVD4A6gnEDqLsq9ZuHBx54QPfff7+6d+8um82mjIwMDRo0yNW1AajFGDeAuqtSMw8hISGSpOPHj2vHjh3Kzc1Vt27dXFoYgNqNcQOouyo18zBq1CgNGDBAAwcOVHFxsd59913Fx8fr9ddfd3V9AGopxg2g7qrUzMMvv/yigQMHSpK8vb314IMPKj8/36WFAajdGDeAuqvSP5jMzc113i8oKJBlWS4rCkDtx7gB1F2V2m3x4IMPqnfv3urSpYtsNpvWrVvHaWYBnBPjBlB3VSo89O3bV+3atdOGDRvk7u6uv/3tb7rmmmtcXRuAWoxxA6i7KhUeJMnf31/+/v6urAVAHcO4AdRNlfrNAwAAwEmEBwAAYITwAAAAjBAeAACAEcIDgBpl2rRp6tGjhyIiIvTmm29KktatW6fIyEiFhoZq6tSpzr5bt25VVFSUwsLClJCQoNLS0uoqG6hXCA8AaoxNmzZpw4YNSk9P16JFizRv3jx9++23io+P1+zZs5WRkaHs7GytWbNGkhQXF6cxY8ZoxYoVsixLKSkp1fwKgPqB8ACgxujYsaPmzp0rDw8P7d+/X2VlZTp8+LBatWqlli1bysPDQ5GRkcrMzNSePXtUVFSkwMBASVJUVJQyMzOr9wUA9QThAUCN4unpqenTpysiIkJBQUHKy8uTr6+v83G73a7c3Nwz2n19fcudDhuA61T6JFEAcKE89thjGjJkiB599FHl5OTIZrM5H7MsSzabTQ6H46ztJnx8LqmymnFuvr6NqrsEnOJ83w/CA4AaY8eOHSopKdF1112nhg0bKjQ0VJmZmXJ3d3f2yc/Pl91uV/PmzctdpbOgoEB2u91offv3F8rhOPfFuvijVzXy849U2bJ4T85fZd4PNzdbhQGb3RYAaozdu3crMTFRJSUlKikp0ccff6zo6Gjt3LlTu3btUllZmZYtW6bg4GD5+fnJ29tbWVlZkqS0tDQFBwdX8ysA6gdmHgDUGCEhIdqyZYt69+4td3d3hYaGKiIiQs2aNVNsbKyKi4sVEhKi8PBwSVJycrISExNVWFiogIAADRw4sJpfAVA/EB4A1CixsbGKjY0t1xYUFKT09PQz+vr7+ys1NfVClQbg/7DbAgAAGCE8AAAAI4QHAABgxKXhobCwUD179tTu3bslSaNHj1ZoaKh69eqlXr166cMPP5TE+ekBAKhNXBYevvrqK/Xr1085OTnOtuzsbL399ttKS0tTWlqaunXrJonz0wMAUJu4LDykpKRo7NixzpO2/Prrr9q7d6/i4+MVGRmp6dOny+FwcH56AABqGZcdqjlhwoRy9wsKCtSpUyeNHTtWjRo10tChQ5Wamqq2bdtyfnoAAGqRC3aeh5YtW2rWrFnO+zExMVq6dKnatGlz3uenl+rnOeo5Retv2Ba/YVsAcLULFh62bdumnJwchYWFSToREjw8PKrk/PRSxeeor8sDqem54tkWv6lv2+Jc56gHAFMX7FBNy7I0ceJEHTp0SMePH9fChQvVrVs3zk8PAEAtc8FmHvz9/fXII4+oX79+Ki0tVWhoqHr27CmJ89MDAFCbuDw8rFq1ynl7wIABGjBgwBl9OD89AAC1B2eYBAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAAAAjhAcAAGCE8AAAAIwQHgAAgBHCAwAAMEJ4AAAARggPAADACOEBAAAYITwAqFFmzpypiIgIRUREaMqUKZKkdevWKTIyUqGhoZo6daqz79atWxUVFaWwsDAlJCSotLS0usoG6hXCA4AaY926dVq7dq2WLFmipUuX6ptvvtGyZcsUHx+v2bNnKyMjQ9nZ2VqzZo0kKS4uTmPGjNGKFStkWZZSUlKq+RUA9QPhAUCN4evrq1GjRsnLy0uenp5q06aNcnJy1KpVK7Vs2VIeHh6KjIxUZmam9uzZo6KiIgUGBkqSoqKilJmZWb0vAKgnCA8Aaoy2bds6w0BOTo6WL18um80mX19fZx+73a7c3Fzl5eWVa/f19VVubu6FLhmolzyquwAAON327ds1dOhQjRw5Uu7u7srJyXE+ZlmWbDabHA6HbDbbGe0mfHwuqaqS8Tt8fRtVdwk4xfm+H4QHADVKVlaWHnvsMcXHxysiIkKbNm1Sfn6+8/H8/HzZ7XY1b968XHtBQYHsdrvRuvbvL5TDYZ2zD3/0qkZ+/pEqWxbvyfmrzPvh5marMGCz2wJAjbFv3z4NGzZMycnJioiIkCTdcMMN2rlzp3bt2qWysjItW7ZMwcHB8vPzk7e3t7KysiRJaWlpCg4Ors7ygXqDmQcANcacOXNUXFysyZMnO9uio6M1efJkxcbGqri4WCEhIQoPD5ckJScnKzExUYWFhQoICNDAgQOrq3SgXnFpeCgsLFR0dLReeeUVXXnllVq3bp0mTZqk4uJide/eXU888YSkE8dqJyQk6OjRo7rppps0fvx4eXiQa4D6JjExUYmJiWd9LD09/Yw2f39/paamurosAKdx2W6Lr776Sv369XP+0KmoqIhjtQEAqANcFh5SUlI0duxY5w+YtmzZwrHaAADUAS7bNzBhwoRy908/Jruqj9Wuj4dc8Yvj37AtfsO2AOBqF+yHBRUdk10Vx2pLFR9yVZcHUtNDn9gWv6lv2+Jch1wBgKkLdqjm6cdkV+Wx2gAA4MK5YOGBY7UBAKgbLthuC29vb47VBgCgDnB5eFi1apXzdlBQEMdqAwBQy3F6agAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPACoUQoLC9WzZ0/t3r1bkrRu3TpFRkYqNDRUU6dOdfbbunWroqKiFBYWpoSEBJWWllZXyUC9Q3gAUGN89dVX6tevn3JyciRJRUVFio+P1+zZs5WRkaHs7GytWbNGkhQXF6cxY8ZoxYoVsixLKSkp1Vg5UL8QHgDUGCkpKRo7dqzsdrskacuWLWrVqpVatmwpDw8PRUZGKjMzU3v27FFRUZECAwMlSVFRUcrMzKzGyoH6xaM6VhoTE6MDBw7Iw+PE6p999lkdPXpUkyZNUnFxsbp3764nnniiOkoDUI0mTJhQ7n5eXp58fX2d9+12u3Jzc89o9/X1VW5u7gWrE6jvLnh4sCxLOTk5Wr16tTM8FBUVKTw8XPPmzVOLFi00dOhQrVmzRiEhIRe6PAA1iMPhkM1mc963LEs2m63CdlM+PpdUSZ34fb6+jaq7BJzifN+PCx4efvjhB0nSww8/rIMHD+q+++7TNddc45yalOScmiQ8APVb8+bNlZ+f77yfn58vu91+RntBQYFzV4eJ/fsL5XBY5+zDH72qkZ9/pMqWxXty/irzfri52SoM2Bf8Nw+HDx9WUFCQZs2apbfeeksLFizQ3r17zzo1CaB+u+GGG7Rz507t2rVLZWVlWrZsmYKDg+Xn5ydvb29lZWVJktLS0hQcHFzN1QL1xwWfeWjfvr3at2/vvN+3b19Nnz5dHTp0cLb9kSnI+jj9SPr+DdviN3VpW3h7e2vy5MmKjY1VcXGxQkJCFB4eLklKTk5WYmKiCgsLFRAQoIEDB1ZztUD9ccHDw+bNm3X8+HEFBQVJOhEU/Pz8zjo1aaKi6ce6NJCeznQakG3xm/q2Lc41/VgTrVq1ynk7KChI6enpZ/Tx9/dXamrqhSwLwP+54Lstjhw5oilTpqi4uFiFhYVasmSJnnzyybNOTQIAgJrngs883H777frqq6/Uu3dvORwO9e/fX+3bt69wahIAANQs1XKeh8cff1yPP/54ubaKpiYBAEDNwhkmAQCAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGCA8AAMAI4QEAABghPAAAACOEBwAAYITwAAAAjBAeAACAEcIDAAAwQngAAABGalR4eP/999WjRw+FhoZq/vz51V0OgFqAcQO48Dyqu4CTcnNzNXXqVC1evFheXl6Kjo7WLbfcoquvvrq6SwNQQzFuANWjxsw8rFu3Tp06dVKTJk100UUXKSwsTJmZmdVdFoAajHEDqB41ZuYhLy9Pvr6+zvt2u11btmyp9PPd3GwVPnZZ04vPq7aa6lyvuSJejX1cUEn1+yPb4rJLmrmgkup3tm3xR7ZPbeDKceNUdXUMuZCq+jNYV8eyC6Uy78e5+tSY8OBwOGSz/VaoZVnl7v+epuf4ck8f3ft8SquxfHwuMX7O9Y8+74JKqt8f2RbJ9451QSXV749si9rKlePGqerqGHIhVfXnsq6OZRfK+b4fNWa3RfPmzZWfn++8n5+fL7vdXo0VAajpGDeA6lFjwsOtt96q9evX68CBA/r111+1cuVKBQcHV3dZAGowxg2getSY3RaXX365nnjiCQ0cOFDHjx9X37599de//rW6ywJQgzFuANXDZlmWVd1FAACA2qPG7LYAAAC1A+EBAAAYITwAAAAjhAcAAGCE8AAAAIwQHk6xevVqvfnmm1W+3I8//ljTpk2TJE2fPl2bN2+WJCUkJOjrr7+u8vVV1saNGxUTE+PSZS5dulQRERHq2bOn/vvf/zrbf/rpJ8XHx1fpuk86cuSIhg0bdt7L2b17t+64446zPvbZZ58pMjJS4eHh+uijj857XSe54vNRVdsDZs72/crNzdWQIUPO+bwZM2ZoxowZlV7P119/rYSEhHP2mTZtmj7++ONKL7Ouc8XYJ0nvvvuu3n333XP2GTJkiHJzc6t83RdajTnPQ02QnZ3tkuXeeeeduvPOOyVJX3zxhW655RZJ0oQJE1yyvppkwoQJev/997Vhwwa99tprevnllyVJe/fu1U8//eSSdR46dEhbt251ybJPevHFFzV27InTWz/77LO66667qmS5rvh8XIjtgcq5/PLL9frrr1fpMq+//npdf/315+zzz3/+s0rXibPr16/f7/ap6ve/utSL8PDaa69p+fLlKisr02233aYbb7xRL7zwgtLT0/Xzzz8rJiZGU6dO1YIFCyRJV1xxhfbu3asvv/xS+/bt0wMPPKDOnTtr3LhxOnjwoBo0aKBnnnlGf/nLXzRq1Cg1bNhQ//vf/3T48GE9+eSTSktL07fffqu77rpLo0aN0uLFi7Vp0yZ16tRJ2dnZSkxM1MyZM5WUlKThw4frlltuOaPGuLg4HT16VE8++aQKCgokScOGDXOGkKpy4MABDRkyRD/++KNat26t6dOnKyMjQ//5z3/kcDgUEBCgsWPHytvbW2+//bbS0tL066+/ytPTUy+++KKuuuoqrV27VpMmTZK3t7dat25dbvlt2rTRxo0blZWVpRtvvNHZnpSUpN27d2v8+PEaO3asXnnlFaWnp8vd3V2dO3dWXFyc3N3dtXTp0rPWci5JSUnKy8vTsGHDtGPHDjVt2lQNGjRQZGSkNm3apMmTJ0uSYmJiNHz4cEnSq6++qgYNGmjHjh269tprlZycXG6ZK1as0KxZs/TWW2+pWbNmatOmjTZv3izLssq9ro0bN+qVV16Rp6enc+bioosucs5OvPbaa7rssst07bXXatu2bZL0u58PSZo9e7Y8PDy0e/du/fWvf9WECRPk5eWlqVOnav369Tp06JDsdrumTp2qyy67TJ06dVK7du2Un58vX19f5/aYNWvWH/mY4A86/fs1cuRIDR48WKtWrdLPP/+sp556SocOHdI111yjL774Qp9++qkkacuWLYqOjlZubq6ioqIUGxtb4To2btyomTNnat68eYqJidH111+vrKwsHThwQImJiQoJCdGoUaPUsWNHdezYUQMHDtSqVaskyTnDERsbW+4z06ZNG3Xq1En33XefpBPflaeeeko33HCDi7fYhbVz506NGTNGBw8e1EUXXaSEhAS5ublp/Pjxeu+993Ts2DF17NhR8+fP1w033KAxY8YoKChI3bt3P+vyTt2et912m8LCwpSVlSV3d3e99NJLatmype644w7NnTtXmzZtqnA8euGFF+RwONSmTRtlZWVpzpw5at26tY4dO6bu3btr5cqVvzsOulqd323x6aefKjs7W6mpqVq6dKlyc3N19OhRBQYG6pVXXtHo0aP19NNPq0OHDoqOjlZ0dLT69OkjSSopKVFGRob69++vp59+WnFxcVqyZImee+45PfHEE8515OXlaeHChXrkkUc0evRojR8/XkuXLlVKSoqOHDni7Ne7d2+1a9dOSUlJuvbaa89ZY3p6uj788EP5+flp8eLFmjBhgnM6uyrt3btXY8aM0fLly1VQUKD33ntPKSkpWrBggdLS0uTj46M5c+aosLBQH330kebNm6dly5apa9eumj9/vkpKSjRq1ChNnz5dixcvVoMGDcot/4477tDIkSPl4eFRbro2MTFR7dq109ixY7VmzRqtWrVKixYt0pIlS7Rr1y4tWLBA27dvP2stvycxMVF2u12jR4/Wzp079cILL/zu7qj//ve/zu2wd+9erV271vnY2rVrNWvWLP373/9Ws2bNnK9r6tSp2rJlixITE8st66uvvtL48eO1aNEizZ8/X82aNdPixYt17bXX6oMPPqiwhoo+HyfrS0hIUGZmpoqLizV//nzt2rVLP/zwgxYsWKAVK1aoRYsWSk9PlyT98ssvGjJkiNLS0jRu3DjZ7XaCQzU4/fu1fv1652MTJkxQ9+7d9f777ys8PLzcVPb+/fs1d+5cLVq0yPn9q6zjx49r4cKFGj16tHN3aWWc+pm57777lJaWJknas2ePDhw4UOeCgyTFxcUpJiZG77//vkaPHq1//vOfuuaaa5SXl6cjR45o8+bNaty4sTZt2iRJ2rBhg7p06VKpZefn5ysoKEhLly7VzTffrPnz51e6rpycHP3nP//RCy+8oN69ezu/1ytXrlTXrl2rPThI9SA8rF+/Xlu2bFFUVJTuueceZWdn6/vvv1dCQoLee+89XXbZZYqIiDjrc0+e5vbo0aPKzs7W6NGj1atXL40YMULHjh3TL7/8IknOc+lfccUVatu2rXx8fHTJJZeoSZMmOnTo0B+usX379vroo4/0j3/8Q19//bVL9lv7+/urZcuWcnNzU5s2bfTLL79o165duu+++9SrVy99/PHH+uGHH3TJJZfoxRdf1AcffKAXX3xRq1ev1rFjx7Rt2zbZ7Xa1adNGknTPPfc4lz19+nR98cUXmjJlij766CNt375do0aN0uknNd2wYYMiIiLUsGFDeXh4qE+fPlq/fr02btx41lpM+Pj46Morr/zdfm3btlXz5s2d2+Hk+/bLL78oNjZWvXv31mWXXSZJSk1N1ZtvvqlZs2bpyy+/1Pbt2zVy5EjnAH/NNdeoRYsWatiwoZo2baqgoCBJJz4fhw8fNqr/pJtvvllXXXWVbDabevXqpQ0bNqhVq1Z6+umn9d5772ny5Mn68ssvdezYMedz6uJgX9uc7ft10ueff65evXpJkrp166bGjRs7H+vSpYu8vLzUrFkzNW3atFLjyKnPlU58pg8ePGhU78nPzC233KK8vDzt3r1bS5cuddZZlxw9elQ//vijQkNDJUmBgYG69NJL9cMPP+jWW2/Vxo0btWHDBg0aNEhffPGFvv/+e7Vo0UKXXFL5q1Ge+l6YvIetW7dWo0aNJElRUVFatmyZJGnJkiWKioqq9HJcqc7vtigrK9OgQYP00EMPSZIOHz4sd3d35ebmyt3dXT/88IOKi4vPmuRO/i/a4XDIy8vLmcQl6eeff1aTJk0kSZ6ens52Dw/zTVpRjRdffLGWL1+uzz77TKtXr9a///1vZWRkyM2t6jLfqfXabDY1atRI3bt3d/5v+ujRoyorK9O+ffsUExOjBx54QMHBwbrsssu0detW2Wy2cmHA3d3defs///mPPv74YzVp0kQFBQXq16+fOnXqdMYlkx0Oxxl1lZaWqqys7Ky1mDh1JuT0Wo8fP+68fer7f2o/m82mWbNm6amnnlJERIQuv/xyzZ07V5MmTVJAQIBKS0s1cOBAXXnllc5B5dTPw+nb5FQnLx9dWlr6u6/j1GVYliV3d3dlZ2drxIgRevDBBxUWFiY3N7dyr+/0WSBceKd/v6644grnfXd39zOCdEXPM7mKwMnP8tkuTX76skpLS8ut6+RnxmazqXfv3vrggw+0fPnySs341TZn26aWZamsrExdu3bV+vXrlZ2drTfeeEMLFy7U6tWrdfvttxut49T34vT1nWs8OvW7e+WVV+qKK67QypUrtX///hrzn4I6P/PQqVMnpaWl6ejRoyotLdWwYcOUkZGh0aNHKyEhQR07dnRO7bm7u591IG/UqJH+/Oc/O8PD559/rgEDBvyhetzd3c/4A3i2GlesWKG3335bM2bMUPfu3TV27FgdOHDAaPryj/rwww+1f/9+WZalcePG6T//+Y++/vprtWrVSg8++KCuv/56ffTRRyorK9O1116rgoICffvtt5JUblr+T3/6k3O676abblJJSYl+/fVXFRcXl9vWnTp10gcffKCioiKVlpZq0aJF6tSpk2655Zaz1vJ7PDw8zvo+Nm3aVDt27JBlWfrpp5+cvzk4lyZNmigoKEj9+vVTUlLSGa/ruuuuc4YFk//lNW3aVNu3b5dlWc79z9LZPx+SlJWVpdzcXDkcDi1dulTBwcH64osv1LFjR/Xr109//vOf9cknn5z1uRVtD1SvoKAgvf/++5KkNWvW/OFZKRONGzfWwYMHdeDAAZWUlOizzz6rsG9UVJQWLFigFi1a6PLLL3d5bRfaJZdcoiuvvFIrV66UJH355ZcqKChQ27Zt1blzZ61du1Zubm5q1KiRrrvuOs2dO1ddu3atsvWbjEd9+vRRUlKS7r777ipb//mq8zMPd9xxh7799lvdd999KisrU5cuXfTLL7/Ix8dHoaGhuvXWW9WzZ0+Fhobq5ptv1tNPP+2cnj7VCy+8oHHjxumNN96Qp6enpk6detZk/3u6dOmisWPH6vnnnz9njffcc4/zB5ORkZFyd3dXXFxcualNV2jUqJGGDx+uQYMGyeFw6LrrrtMjjzyi0tJSvfvuu+rRo4csy9LNN9+s7du3y9PTU//6178UFxcnDw8P/eUvf3EuKzk5Wc8884xmzJihiy66SPPnz9frr7+u1atX65ZbbtGRI0cUFxenF154QVu3blWfPn1UWlqq2267TQ888IA8PDzOWsvv8fHx0RVXXKHRo0eXa7/11lu1aNEihYeHq3Xr1urQoUOlt8sjjzyiu+++Wx999JGeeeYZJSQkaMmSJXJzc3Puxlm0aJHatWtXqeWNGDFCjz76qC677DJ16NDBOZ19ts+HJNntdo0cOVK5ubnq3Lmz7r33XhUUFGj48OGKjIyUJLVr1067d++ucHvExMRo3rx5lX7NcK2EhAQ9/fTTSklJkb+/v8u/29KJ7/fgwYPVt29fNW/e/JxHabRo0UItWrQotyuyrjk5rs+YMUOenp6aMWOGvLy85OXlVW77dOrUSd9//73+/Oc/V9m6Tcaj0NBQPfPMMzVq9xFX1QRquFN/TY+6Y+7cubr11lt19dVX65tvvtEzzzyjxYsXu2Rdw4YNc56XpDIsy1JeXp5iYmK0bNkyeXl5uaSu+sbhcCgoKEjLly93/vj691iWpU8//VTvvvuuXnnlFRdXWHl1fuYBAGqiVq1a6cknn5Sbm5u8vb313HPPVdh38+bNFT7+2muvnXO3wmOPPaadO3eqY8eOla5txYoVGjdunMaNG0dwOM1bb72lJUuWnNFut9vPeQ6HkpIS5wx3ZYODJE2cOFGrV6+uceeHYOYBAAAYqfM/mAQAAFWL8AAAAIwQHgAAgBHCQx23ceNG9ezZ8w8//8CBA2ecKtlEQkKC1q1bd84+7777rl577bU/vA4A56+isWLatGlaunTphS/o/+Tm5io6Ovp3+w0ZMkTff//9BagIEkdbwMUqc2XIylyJDkD1qO4rcl5++eXOixaeS007GqGuY+ahHjh27Jgee+wx9erVSzExMdq5c6eOHDmip556Sj179lRkZKSmTJniPAvhypUr1b17d0VFRemll15yLuehhx5SSkqK8/7s2bM1ceLEc647JiZGmZmZ2r17t+666y4999xz6tu3r0JDQ/Xhhx9KOnElumeffVbSiRNmff31187nn7y/e/duhYSE6OGHH1ZYWJhefvlljRgxwtlv8+bN6t279/luKqBeO9tYMWrUKOfpqa+//nrNmDFD0dHRuuOOO/TOO+84nzdy5Ejdf//9CgsLU1RUlPM6NCevFtmjRw/NnDlTN954o/OCgZZlKSwszHmG2rPZvXu32rdvL+nEWDFq1Cj97W9/U3h4uAYNGqS8vDxJv40Vp8+gnHp/xowZ+tvf/qbIyEiNGDFCYWFh+vzzz519ExISKnUWWxAe6oV9+/bpwQcfVFpamnr27KmRI0cqKSlJTZo00fvvv69FixZp27Zt+ve//62CggLFx8drxowZWrx4sfz8/JzLGTBggDM8OBwOpaamVmo68aSffvpJt912m1JTUzVixIjfDR6n+/nnn/WPf/xDK1as0H333adPPvnEeUrolJQUo1oAnOlsY8WpSkpK1LRpUy1YsEDTp0/XpEmTVFxcrE8//VSNGzfWwoULtWLFCrVr167cVSQbN26sjIwMDR8+XJ06dXJeJXLDhg1q0qSJ/P39K13j5s2bNW3aNGVmZqphw4aVmpU41Z49e7RkyRK9+OKL6tevn3NMKyws1KpVq+r0GTWrEuGhHrj22mt14403SpLzqp2rVq3SAw88IJvNJi8vL0VHR+vTTz9VVlaWrrnmGl199dWSpPvvv9+5nNtvv1379+/Xt99+q88++0xXXnmlrrrqqkrX4enpqZCQEEnSX/7yF+Mr/nl4eCgwMFDSiVMud+3aVWlpaTp06JDWrl3rPE0zgD/mbGPFyVmCk+68805JUkBAgEpKSnTs2DGFh4frnnvu0bx585SUlKRNmzaVu8LrTTfd5Lw9YMAAvffee5KkhQsXGu+27Nixo/MidH/5y1+MrlYpnbh65smLgUVFRWndunU6cOCA0tPT1bVr1wtymvC6gPBQD5x+FU6bzeb8d5LD4XDutjj1vGGnXnHP3d1d999/v1JTU7Vo0SLj/+l7eno6aznXdUFOXX9JSYnztpeXV7l6BgwYoEWLFmnZsmUKDQ3VxRdfbFQPgPLONlacfqXg06/aaVmW3nnnHSUkJKhBgwaKjIxUz549y32PL7roIuftW2+9Vb/++qvWr1+vzZs3q3v37kY1nutKuWdrO/VqlafX0rhxY4WHhys9PV2LFi3i91cGCA/1wLZt27R161ZJJ5J+hw4d1KVLF7399tuyLEslJSVKSUnRrbfeqptvvlnff/+9cx/k6efav/fee/XRRx/pm2++Ubdu3aq81mbNmik7O1vSiX2V+fn5Ffa98cYb5ebmpjlz5rDLAqgCZxsrGjZs+LvPW7t2re655x7de++9at26tVatWnXWK7xKJ/649+/fXwkJCerZs6czjFSVZs2aae/evc6r8Z56pd+zGTBggObOnSvLsvTXv/61Smupyzjaoh646qqrNHPmTP3000/y8fHR5MmTddFFFykpKUmRkZE6fvy4unTpokcffVReXl5KTk7WU089JU9PT918883lluXj46N27dqpTZs2zktRV6WnnnpK48aN08KFCxUQEKCAgIBz9o+KilJGRobRPlMAZ3e2sWLGjBm/+7yHH35YY8aMUWpqqqQTuwa+++67Cvvfc889ev7558vtFq0qV199taKjo9WnTx/5+vqqa9eu5X6EfTp/f39deuml/AfEENe2gJEDBw6ob9++mj9/vlq0aFEly5w0aZI8PDwUFxdn9LzS0lINHz5cd999t3r06FEltQBwvQ8++EBLlizRG2+8USXLsyxLnTp10jvvvKM2bdoYPffHH390HhVWmVkWnMDMAyotJSVF//rXvxQbG+sMDhs2bNCkSZPO2v+WW25RfHz8OZcZFxenTZs2aebMmUa1fP/99+rXr5/uuuuuSl9mGED1i4mJ0YEDBzR79mxn28SJE7Vx48az9h89erQ6depU4fJyc3N17733KiAgQK1btzaqZdq0aUpJSdH48eMJDoaYeQAAAEb4wSQAADBCeAAAAEYIDwAAwAjhAQAAGCE8AAAAI4QHAABg5P8D+9kjWRmrV48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax =plt.subplots(1, 2, figsize = (8,8))\n",
    "fig.tight_layout(pad=3.0)\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.countplot(x=\"body_injury\", data=train_data2, ax=ax[0])\n",
    "plt.title(\"Task2 Class Balance\", y=1.02)\n",
    "\n",
    "sns.countplot(x=\"binary_injury\", data=train_data, ax=ax[1])\n",
    "plt.title(\"Task1 Class Balance\", y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f2839",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf1c097e-c88b-4e29-a330-9d1f41289524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the narrative to lowercase\n",
    "def preprocess_text(text):\n",
    "    if type(text) == float:\n",
    "        print(text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "    \n",
    "final1.NARRATIVE = final1.NARRATIVE.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "992a3678-20ab-471b-9bb9-5ea2a6ca7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "final2.NARRATIVE = final2.NARRATIVE.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab43b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final1.NARRATIVE.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dac0ac52-2059-40ee-9a9a-45fd5d8feb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1756"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final2.NARRATIVE.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8cd5955f-9dd0-4352-b454-f7be4c200993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>while bolting with a jackleg, a rock fell from...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>the employee was assisting a bolter operator b...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>during lubrication of wire being installed in ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>employee was working on loader. he accidentall...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>employee was scraping cement from forms outdoo...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  binary_injury                                          NARRATIVE  split\n",
       "0   high_injury  while bolting with a jackleg, a rock fell from...  train\n",
       "1   high_injury  the employee was assisting a bolter operator b...  train\n",
       "2   high_injury  during lubrication of wire being installed in ...  train\n",
       "3   high_injury  employee was working on loader. he accidentall...  train\n",
       "4   high_injury  employee was scraping cement from forms outdoo...  train"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6b6d395-83ff-4195-a454-7f04861d8553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extremities</td>\n",
       "      <td>sand covered rock that employee stepped on</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extremities</td>\n",
       "      <td>piece of rock fell on leg while splitting rock...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extremities</td>\n",
       "      <td>employee stepped off bolter, placed foot on un...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extremities</td>\n",
       "      <td>ee was using a ratchet to tighten a bolt and r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extremities</td>\n",
       "      <td>while tightening conveyor chain on buggy, ee p...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_injury                                          NARRATIVE  split\n",
       "0  extremities         sand covered rock that employee stepped on  train\n",
       "1  extremities  piece of rock fell on leg while splitting rock...  train\n",
       "2  extremities  employee stepped off bolter, placed foot on un...  train\n",
       "3  extremities  ee was using a ratchet to tighten a bolt and r...  train\n",
       "4  extremities  while tightening conveyor chain on buggy, ee p...  train"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a967748",
   "metadata": {},
   "source": [
    "### Tokenize and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5546828-8e73-45dd-9d51-576038c296f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizeing the narrative in task1 and task2\n",
    "narrative1 = list(final1.NARRATIVE.values)\n",
    "narrative2 = list(final2.NARRATIVE.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2bfcc87-1ee6-4f67-9d69-22e234bb9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_narrative1=nlp(str(narrative1))\n",
    "doc_narrative2=nlp(str(narrative2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "48677ad4-98e0-4cea-80c0-3741fd1021a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract token of narrative in task1\n",
    "narrative_words = []\n",
    "narrative_lemma_words_lower=[]    \n",
    "for token in doc_narrative1:\n",
    "    if not token.is_punct:\n",
    "        narrative_words.append(token)\n",
    "        narrative_lemma_words_lower.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62291e90-17e5-4796-913d-09450f4238ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4551"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(narrative_lemma_words_lower)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61eac40",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af4c440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72897060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using stemming for narrative in task1\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "ps = PorterStemmer()\n",
    "\n",
    "narrative_words_stem = []\n",
    "narrative_stem_words_lower=[]\n",
    "\n",
    "for sen in narrative1:\n",
    "    new_words = tokenizer.tokenize(sen)                              \n",
    "    for word in new_words:\n",
    "        narrative_words_stem.append(word)\n",
    "        narrative_stem_words_lower.append(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80e79d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3791"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(narrative_stem_words_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "987ca9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1212"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the diffrent words bewteen stem and lemma\n",
    "len(set(narrative_stem_words_lower) - set(narrative_lemma_words_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ecae4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the diffrent between lemma and stem \n",
    "len(set(narrative_lemma_words_lower) - set(narrative_stem_words_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "252725d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2579"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The same word in lemma and stem\n",
    "len(set(narrative_lemma_words_lower) & set(narrative_stem_words_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5caf1d",
   "metadata": {},
   "source": [
    "Comparing with lemmatize and stemming, stemming has a stronger ability of transfering words to its basic root form. some words transfered by stemming are not be the dictionary words, which is difficult for people to understand. So in the follwing tasks, we use lemmatize to restoration the words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77275a8",
   "metadata": {},
   "source": [
    "### Using lemma words to create the dataset for task1 and task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3393140-17ca-4a2a-8ad3-8a3772661bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset for task1 with lemma words\n",
    "list_column=[]\n",
    "\n",
    "for sent in narrative1:\n",
    "    words_token = nlp(str(sent))\n",
    "    strword = ''\n",
    "    for token in words_token:\n",
    "        if not token.is_punct:\n",
    "            if not token.is_stop:\n",
    "                strword += ' ' + token.lemma_\n",
    "                list(strword)\n",
    "    list_column.append(strword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1469453a-7db6-49e0-93c8-f9a9c5e71f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset for task2 with lemma words\n",
    "list_column1=[]\n",
    "\n",
    "for sent in narrative2:\n",
    "    words_token = nlp(str(sent))\n",
    "    strword = ''\n",
    "    for token in words_token:\n",
    "        if not token.is_punct:\n",
    "            if not token.is_stop:\n",
    "                strword += ' ' + token.lemma_\n",
    "                list(strword)\n",
    "    list_column1.append(strword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ddbeaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final1.NARRATIVE = list_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4e20ca4-e292-43d0-b1f3-f776fe84d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>bolt jackleg rock fall rib</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>employee assist bolter operator make bolt pos...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>lubrication wire instal electrical conduit em...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>employee work loader accidentally step home l...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>employee scrape cement form outdoors snow for...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  binary_injury                                          NARRATIVE  split\n",
       "0   high_injury                         bolt jackleg rock fall rib  train\n",
       "1   high_injury   employee assist bolter operator make bolt pos...  train\n",
       "2   high_injury   lubrication wire instal electrical conduit em...  train\n",
       "3   high_injury   employee work loader accidentally step home l...  train\n",
       "4   high_injury   employee scrape cement form outdoors snow for...  train"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54408080-8b3c-4ac2-b430-726167b4b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "final2.NARRATIVE = list_column1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2c44a13-8f15-4791-813d-25a537fd9c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extremities</td>\n",
       "      <td>sand cover rock employee step</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extremities</td>\n",
       "      <td>piece rock fall leg splitting rock put rock p...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extremities</td>\n",
       "      <td>employee step bolter place foot uneven ground...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extremities</td>\n",
       "      <td>ee ratchet tighten bolt ratchet slip cause st...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extremities</td>\n",
       "      <td>tighten conveyor chain buggy ee right foot ra...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_injury                                          NARRATIVE  split\n",
       "0  extremities                      sand cover rock employee step  train\n",
       "1  extremities   piece rock fall leg splitting rock put rock p...  train\n",
       "2  extremities   employee step bolter place foot uneven ground...  train\n",
       "3  extremities   ee ratchet tighten bolt ratchet slip cause st...  train\n",
       "4  extremities   tighten conveyor chain buggy ee right foot ra...  train"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac114d",
   "metadata": {},
   "source": [
    "### Remove stop words (rank words according to TF/IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8061d245-8895-4756-a2c2-a18f9d6ee054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(corpus):\n",
    "    for conversation in corpus:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(conversation), deacc=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b73bd5d5-a372-4e99-8b67-79f37e9e2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove functuations and tranfer sentence to words \n",
    "doc_tokenized = list(sent_to_words(list(final1.NARRATIVE.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f70d330-51e9-4d0d-9d9a-132b0689d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokenized1 = list(sent_to_words(list(final2.NARRATIVE.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c021e4bc-b7e2-480d-acaf-fd99ba33db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer words in each doc to bag of words\n",
    "dictionary = Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a6d3122-1a95-4d8d-9763-cd7f340f7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer words in each doc to bag of words\n",
    "dictionary1 = Dictionary()\n",
    "BoW_corpus1 = [dictionary1.doc2bow(doc, allow_update=True) for doc in doc_tokenized1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50e0e447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bolt', 1], ['fall', 1], ['jackleg', 1], ['rib', 1], ['rock', 1]]\n",
      "\n",
      "\n",
      "[['bolt', 2], ['rock', 1], ['ankle', 1], ['assist', 1], ['bolter', 1], ['cause', 1], ['damage', 1], ['employee', 3], ['extended', 1], ['fracture', 1], ['hand', 1], ['hyper', 1], ['knee', 2], ['leg', 1], ['ligament', 1], ['low', 1], ['make', 1], ['operator', 2], ['plus', 1], ['position', 1], ['possible', 1], ['strike', 1], ['sustain', 1]]\n",
      "\n",
      "\n",
      "[['cause', 2], ['employee', 1], ['hand', 2], ['box', 3], ['conduit', 1], ['edge', 1], ['electrical', 2], ['glove', 1], ['grab', 1], ['guard', 1], ['improper', 1], ['instal', 1], ['laceration', 1], ['left', 1], ['lubrication', 1], ['pull', 1], ['reach', 1], ['repair', 1], ['require', 1], ['result', 1], ['root', 1], ['slip', 1], ['slippery', 1], ['stand', 1], ['stitch', 1], ['surface', 1], ['surgical', 1], ['tendon', 1], ['use', 1], ['wear', 1], ['wet', 1], ['wire', 2]]\n",
      "\n",
      "\n",
      "[['fall', 1], ['ankle', 1], ['cause', 1], ['employee', 1], ['knee', 1], ['accidentally', 1], ['floor', 1], ['home', 1], ['lift', 1], ['loader', 1], ['right', 1], ['step', 1], ['twist', 1], ['work', 1]]\n",
      "\n",
      "\n",
      "[['cause', 1], ['employee', 3], ['hand', 1], ['left', 1], ['slip', 1], ['work', 1], ['advise', 1], ['care', 1], ['cement', 1], ['complete', 2], ['course', 1], ['diagnose', 1], ['dr', 1], ['duty', 1], ['forearm', 2], ['form', 2], ['job', 1], ['old', 1], ['outdoors', 1], ['pt', 1], ['regular', 1], ['return', 1], ['scrape', 1], ['snow', 1], ['strain', 2], ['stretching', 1], ['tendonitis', 1], ['treatment', 1], ['week', 1], ['workpiece', 1], ['year', 1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in BoW_corpus[:5]:\n",
    "    print([[dictionary[id], freq] for id, freq in doc])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4e8e60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bolt', 0.31], ['fall', 0.19], ['jackleg', 0.71], ['rib', 0.51], ['rock', 0.31]]\n",
      "\n",
      "\n",
      "[['bolt', 0.22], ['rock', 0.11], ['ankle', 0.15], ['assist', 0.22], ['bolter', 0.19], ['cause', 0.08], ['damage', 0.19], ['employee', 0.12], ['extended', 0.32], ['fracture', 0.15], ['hand', 0.09], ['hyper', 0.3], ['knee', 0.24], ['leg', 0.14], ['ligament', 0.29], ['low', 0.13], ['make', 0.22], ['operator', 0.3], ['plus', 0.32], ['position', 0.19], ['possible', 0.23], ['strike', 0.1], ['sustain', 0.19]]\n",
      "\n",
      "\n",
      "[['cause', 0.12], ['employee', 0.03], ['hand', 0.13], ['box', 0.42], ['conduit', 0.21], ['edge', 0.14], ['electrical', 0.3], ['glove', 0.14], ['grab', 0.15], ['guard', 0.14], ['improper', 0.2], ['instal', 0.12], ['laceration', 0.1], ['left', 0.06], ['lubrication', 0.25], ['pull', 0.09], ['reach', 0.13], ['repair', 0.12], ['require', 0.1], ['result', 0.1], ['root', 0.22], ['slip', 0.06], ['slippery', 0.19], ['stand', 0.12], ['stitch', 0.1], ['surface', 0.15], ['surgical', 0.22], ['tendon', 0.2], ['use', 0.17], ['wear', 0.13], ['wet', 0.16], ['wire', 0.3]]\n",
      "\n",
      "\n",
      "[['fall', 0.12], ['ankle', 0.27], ['cause', 0.15], ['employee', 0.07], ['knee', 0.22], ['accidentally', 0.57], ['floor', 0.29], ['home', 0.41], ['lift', 0.24], ['loader', 0.25], ['right', 0.13], ['step', 0.2], ['twist', 0.25], ['work', 0.17]]\n",
      "\n",
      "\n",
      "[['cause', 0.06], ['employee', 0.08], ['hand', 0.06], ['left', 0.05], ['slip', 0.06], ['work', 0.06], ['advise', 0.19], ['care', 0.18], ['cement', 0.15], ['complete', 0.31], ['course', 0.21], ['diagnose', 0.12], ['dr', 0.12], ['duty', 0.1], ['forearm', 0.27], ['form', 0.35], ['job', 0.15], ['old', 0.14], ['outdoors', 0.24], ['pt', 0.21], ['regular', 0.18], ['return', 0.11], ['scrape', 0.17], ['snow', 0.16], ['strain', 0.18], ['stretching', 0.24], ['tendonitis', 0.22], ['treatment', 0.12], ['week', 0.16], ['workpiece', 0.24], ['year', 0.17]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate tfidf\n",
    "import numpy as np\n",
    "tfidf = TfidfModel(BoW_corpus, smartirs='ntc')\n",
    " \n",
    "for doc in tfidf[BoW_corpus[:5]]:\n",
    "    print([[dictionary[id], np.around(freq,decimals=2)] for id, freq in doc])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2939691b-0d49-453f-8596-eeb80b26f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cover', 0.57], ['employee', 0.1], ['rock', 0.3], ['sand', 0.69], ['step', 0.31]]\n",
      "\n",
      "\n",
      "[['rock', 0.42], ['accident', 0.18], ['alecia', 0.35], ['clifford', 0.35], ['fall', 0.15], ['happen', 0.27], ['leg', 0.14], ['mb', 0.35], ['noi', 0.35], ['pallet', 0.21], ['piece', 0.11], ['put', 0.19], ['splitting', 0.32]]\n",
      "\n",
      "\n",
      "[['employee', 0.05], ['step', 0.15], ['ankle', 0.2], ['bolter', 0.25], ['boot', 0.29], ['diagnose', 0.23], ['duty', 0.2], ['foot', 0.16], ['ground', 0.19], ['left', 0.1], ['light', 0.27], ['negative', 0.34], ['place', 0.18], ['release', 0.2], ['strain', 0.17], ['turn', 0.21], ['uneven', 0.34], ['walk', 0.17], ['xray', 0.38]]\n",
      "\n",
      "\n",
      "[['bolt', 0.19], ['cause', 0.13], ['ee', 0.09], ['ratchet', 0.86], ['slip', 0.14], ['strike', 0.14], ['tighten', 0.31], ['wrist', 0.26]]\n",
      "\n",
      "\n",
      "[['leg', 0.27], ['foot', 0.11], ['ground', 0.14], ['ee', 0.06], ['slip', 0.09], ['tighten', 0.19], ['break', 0.13], ['buggy', 0.31], ['chain', 0.17], ['conveyor', 0.16], ['jam', 0.23], ['jump', 0.22], ['plateau', 0.34], ['rachet', 0.61], ['right', 0.14], ['tibia', 0.28]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate tfidf\n",
    "import numpy as np\n",
    "tfidf1 = TfidfModel(BoW_corpus1, smartirs='ntc')\n",
    " \n",
    "for doc in tfidf1[BoW_corpus1[:5]]:\n",
    "    print([[dictionary1[id], np.around(freq,decimals=2)] for id, freq in doc])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0efa3e50-44d3-45c2-900c-958540f6d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract stop word in task1 that tfidf <= 0.1\n",
    "without_stopword=[]\n",
    "stopword = []\n",
    "for sentence in tfidf[BoW_corpus]:\n",
    "    for word in sentence:\n",
    "        if word[1]>0.1:\n",
    "            without_stopword.append(word)\n",
    "        else:\n",
    "            stopword.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d033aed-c6d5-4d38-aec1-03a3f263ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract stop word in task2 that tfidf <= 0.1 multi\n",
    "without_stopword1=[]\n",
    "stopword1 = []\n",
    "for sentence in tfidf1[BoW_corpus1]:\n",
    "    for word in sentence:\n",
    "        if word[1]>0.1:\n",
    "            without_stopword1.append(word)\n",
    "        else:\n",
    "            stopword1.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ac9126a7-1fb4-47ff-967f-266f3aaa67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop word that tfidf <= 0.1 in task1\n",
    "list_column = []\n",
    "\n",
    "for sentence in tfidf[BoW_corpus]:\n",
    "    strword = ''\n",
    "    for word in sentence:\n",
    "        #print(dictionary[word[0]])\n",
    "        if word[1]>0.1:\n",
    "            #print(word[1], '--->', dictionary[word[0]])\n",
    "            strword += ' ' + dictionary[word[0]]\n",
    "            list(strword)\n",
    "    list_column.append(strword)\n",
    "    \n",
    "#list_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3107d3e0-da30-4013-87b3-a006079974db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop word that tfidf <= 0.1 in task2\n",
    "list_column1 = []\n",
    "\n",
    "for sentence in tfidf1[BoW_corpus1]:\n",
    "    strword = ''\n",
    "    for word in sentence:\n",
    "        #print(dictionary[word[0]])\n",
    "        if word[1]>0.1:\n",
    "            #print(word[1], '--->', dictionary[word[0]])\n",
    "            strword += ' ' + dictionary[word[0]]\n",
    "            list(strword)\n",
    "    list_column1.append(strword)\n",
    "    \n",
    "#list_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5566452f-dddd-437d-b1e6-d009ab6a4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "final1.NARRATIVE = list_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81f4d250-c28e-4bc9-8466-1e2562c86db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final2.NARRATIVE = list_column1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3eb2b4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>bolt fall jackleg rib rock</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>bolt rock ankle assist bolter damage employee...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>cause hand box conduit edge electrical glove ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>fall ankle cause knee accidentally floor home...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>advise care cement complete course diagnose d...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>process continue shaft run winch raising work...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>employee left pull feel help pain shoulder ti...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>low_injury</td>\n",
       "      <td>feel remove small material eye site med build...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>strike pull right forearm bar fly belt red devil</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>high_injury</td>\n",
       "      <td>fall rib rock cause left step diagnose go ome...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     binary_injury                                          NARRATIVE  split\n",
       "0      high_injury                         bolt fall jackleg rib rock  train\n",
       "1      high_injury   bolt rock ankle assist bolter damage employee...  train\n",
       "2      high_injury   cause hand box conduit edge electrical glove ...  train\n",
       "3      high_injury   fall ankle cause knee accidentally floor home...  train\n",
       "4      high_injury   advise care cement complete course diagnose d...  train\n",
       "...            ...                                                ...    ...\n",
       "1984   high_injury   process continue shaft run winch raising work...   test\n",
       "1985   high_injury   employee left pull feel help pain shoulder ti...   test\n",
       "1986    low_injury   feel remove small material eye site med build...   test\n",
       "1987   high_injury   strike pull right forearm bar fly belt red devil   test\n",
       "1988   high_injury   fall rib rock cause left step diagnose go ome...   test\n",
       "\n",
       "[1989 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c804d689-38a2-4445-b658-5b9280d344b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extremities</td>\n",
       "      <td>bolt jackleg rib rock</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extremities</td>\n",
       "      <td>jackleg ankle assist bolter cause damage empl...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extremities</td>\n",
       "      <td>rock ligament low make operator plus position...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extremities</td>\n",
       "      <td>instal laceration lubrication pull reach repa...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extremities</td>\n",
       "      <td>employee position possible repair result root...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>extremities</td>\n",
       "      <td>laceration tendon hang trip methane tire clea...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>extremities</td>\n",
       "      <td>rock course center lbsledge shoulder bracket ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>trunk&amp;mutipart</td>\n",
       "      <td>hyper knee instal complete miner reinstall su...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>extremities</td>\n",
       "      <td>employee hyper left reach curtain equipment m...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>trunk&amp;mutipart</td>\n",
       "      <td>employee instal reach bridge reinstall attemp...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1756 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         body_injury                                          NARRATIVE  split\n",
       "0        extremities                              bolt jackleg rib rock  train\n",
       "1        extremities   jackleg ankle assist bolter cause damage empl...  train\n",
       "2        extremities   rock ligament low make operator plus position...  train\n",
       "3        extremities   instal laceration lubrication pull reach repa...  train\n",
       "4        extremities   employee position possible repair result root...  train\n",
       "...              ...                                                ...    ...\n",
       "1751     extremities   laceration tendon hang trip methane tire clea...   test\n",
       "1752     extremities   rock course center lbsledge shoulder bracket ...   test\n",
       "1753  trunk&mutipart   hyper knee instal complete miner reinstall su...   test\n",
       "1754     extremities   employee hyper left reach curtain equipment m...   test\n",
       "1755  trunk&mutipart   employee instal reach bridge reinstall attemp...   test\n",
       "\n",
       "[1756 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30e8ca51-cd29-4143-bf7c-73961ecec072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_injury    1128\n",
       "low_injury      861\n",
       "Name: binary_injury, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1[\"binary_injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef289db3-cc74-4466-bf2e-275b652546b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "head&toe          597\n",
       "extremities       593\n",
       "trunk&mutipart    566\n",
       "Name: body_injury, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2[\"body_injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "52d246ba-f220-40a6-b225-2864ba76a2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [binary_injury, NARRATIVE, split]\n",
       "Index: []"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1[pd.isnull(final1.binary_injury)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be5856b8-f434-4389-ae1c-b27088f8758e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_injury</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [body_injury, NARRATIVE, split]\n",
       "Index: []"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2[pd.isnull(final2.body_injury)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1e4328d7-7ec6-4374-bb92-7d989f352afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final1 to csv\n",
    "final1.to_csv('final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02dece09-70e1-4913-821a-67c8abc39edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final1 to csv\n",
    "final2.to_csv('final2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb781e2",
   "metadata": {},
   "source": [
    "These are the final used datasets for Task1 and Task2. The NARRATIVE in the dataset are prepareing by words lemmatization and removing stop words using spacy and TFIDF. The NARRATIVE will be transfered to vectorior type for the model use in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bc599",
   "metadata": {},
   "source": [
    "## Task 1: Binary Document Classification\n",
    "\n",
    "### Feed-forward Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402576c4",
   "metadata": {},
   "source": [
    "The FFNN model use one hot encoding to convert NARRATIVE inputs to vectorized minibatches. The one hot encoding is calling by 'vectorize' function that is implemented inside the 'ReviewVectorizer' class shown in the attached file of 'models.py'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9f717d71-73fc-4448-94f1-71dbd040a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Models import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7cfe5be3-d393-4d0e-87c5-832adbf345e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training \n",
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    body_csv=\"/Users/yuanbo/Desktop/cits4012/final1.csv\",\n",
    "    frequency_cutoff=25,\n",
    "    model_state_file='model.pth',\n",
    "    save_dir='/Users/yuanbo/Desktop/cits4012',\n",
    "    vectorizer_file='vectorizer.json',\n",
    "    # No model hyperparameters\n",
    "    # Training hyperparameters\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.03,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "    # Runtime options\n",
    "    cuda=True,\n",
    "    reload_from_files=False,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "31b178ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            }\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "#dataset and vectorizer\n",
    "final1 = pd.read_csv(args.body_csv)\n",
    "dataset = InjuryDataset.load_dataset_and_make_vectorizer(final1)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# model\n",
    "classifier = InjuryClassifier(num_features=len(vectorizer.NARRATIVE_vocab))\n",
    "classifier = classifier.to(args.device)\n",
    "# loss and optimizer\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1fcf43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_binary(y_pred, y_target):\n",
    "    y_target = y_target.cpu()\n",
    "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "45912344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state['epoch_index'] = epoch_index\n",
    "    # Iterate over training dataset\n",
    "    # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "    dataset.set_split('train')\n",
    "    batch_generator = generate_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    classifier.train()\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # the training routine is 5 steps:\n",
    "        # step 1. zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # step 2. compute the output\n",
    "        y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
    "        # step 3. compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch-running_loss) / (batch_index + 1)\n",
    "        # step 4. use loss to produce gradients\n",
    "        loss.backward()\n",
    "        # step 5. use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        # compute the accuracy\n",
    "        acc_batch = compute_accuracy_binary(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state['train_acc'].append(running_acc)\n",
    "\n",
    "    # Iterate over val dataset\n",
    "    # setup: batch generator, set loss and acc to 0, set eval mode on\n",
    "    dataset.set_split('val')\n",
    "    batch_generator = generate_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    classifier.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # step 1. compute the output\n",
    "        y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
    "        # step 2. compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "        # step 3. compute the accuracy\n",
    "        acc_batch = compute_accuracy_binary(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "    train_state['val_loss'].append(running_loss)\n",
    "    train_state['val_acc'].append(running_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82baae-11f1-4559-a554-dd8d6329ccd9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800a77a-ca6a-44bb-ad78-ae6cde494e78",
   "metadata": {},
   "source": [
    "We make the test code as a function so that we can compare the result at the end of this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "09171960-2eb1-4d78-8ce6-ccfc4c4a24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ffn(model, args):\n",
    "    classfier = torch.load(model)\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset,batch_size=args.batch_size,device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    classifier.eval()\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "        # compute the accuracy\n",
    "        acc_batch = compute_accuracy_binary(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    return train_state['test_loss'], train_state['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e1e2b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier, \"FFN1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3528ec30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryClassifier(\n",
       "  (fc1): Linear(in_features=238, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('FFN1.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "83ef9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.678\n",
      "Test Accuracy: 71.61\n"
     ]
    }
   ],
   "source": [
    "loss_ffn2, acc_ffn2 = test_ffn(\"FFN1.pt\", args)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(loss_ffn2))\n",
    "print(\"Test Accuracy: {:.2f}\".format(acc_ffn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4266bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier, \"FFN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "44a3ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryClassifier(\n",
       "  (fc1): Linear(in_features=238, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('FFN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eaa4b179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.682\n",
      "Test Accuracy: 71.88\n"
     ]
    }
   ],
   "source": [
    "loss_ffn1, acc_ffn1 = test_ffn(\"FFN.pt\", args)\n",
    "print(\"Test loss: {:.3f}\".format(loss_ffn1))\n",
    "print(\"Test Accuracy: {:.2f}\".format(acc_ffn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94c56c",
   "metadata": {},
   "source": [
    "### A CNN Conv1d based model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b1551",
   "metadata": {},
   "source": [
    "The CNN model use 100 dimention Glove pre-trained word embedding to convert NARRATIVE to 100 dimention vectors. We load the pre-trained word embedding file and produce the word embedding matrix of NARRATIVE by calling 'make_embedding_matrix' function shown below. The produced word embedding are implmented in training CNN by calling the class 'NewsClassifier' shown in the attached 'Models.py' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "70998fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t/Users/yuanbo/Desktop/cits4012/vectorizer.json\n",
      "\t/Users/yuanbo/Desktop/cits4012/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path hyper parameters\n",
    "    news_csv=\"/Users/yuanbo/Desktop/cits4012/final1.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"/Users/yuanbo/Desktop/cits4012\",\n",
    "    # Model hyper parameters\n",
    "    glove_filepath='glove.6B.100d.txt', \n",
    "    use_glove=False,\n",
    "    embedding_size=100, \n",
    "    hidden_dim=100, \n",
    "    num_channels=100, \n",
    "    # Training hyper parameter\n",
    "    seed=1337, \n",
    "    learning_rate=0.01, #0.009     #0.01\n",
    "    dropout_p=0.2,     #0.2~0.3      #0.1\n",
    "    batch_size=128, \n",
    "    num_epochs=150,   \n",
    "    early_stopping_criteria=10, \n",
    "    # Runtime option\n",
    "    cuda=True, \n",
    "    catch_keyboard_interrupt=True, \n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True\n",
    ") \n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9a634e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "args.use_glove = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "abce600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained embeddings\n"
     ]
    }
   ],
   "source": [
    "if args.reload_from_files:\n",
    "    # training from a checkpoint\n",
    "    dataset = NewsDataset.load_dataset_and_load_vectorizer(args.news_csv,\n",
    "                                                           args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Use GloVe or randomly initialized embeddings\n",
    "if args.use_glove:\n",
    "    words = vectorizer.title_vocab._token_to_idx.keys()\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None\n",
    "\n",
    "classifier = NewsClassifier(embedding_size=args.embedding_size, \n",
    "                            num_embeddings=len(vectorizer.title_vocab),\n",
    "                            num_channels=args.num_channels,\n",
    "                            hidden_dim=args.hidden_dim, \n",
    "                            num_classes=len(vectorizer.category_vocab), \n",
    "                            dropout_p=args.dropout_p,\n",
    "                            pretrained_embeddings=embeddings,\n",
    "                            padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "425d5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2812dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "def load_glove_from_file(glove_filepath):\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, encoding=\"utf8\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "67a74b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb698e1f65544ce19c6f19d9e079fb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caf34f9b779486ea4f39aced0669966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc7fb40bdc4029b715d5bce2eb5b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(batch_dict['x_data'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # compute the output\n",
    "            y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3d00ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(modelname, args):  \n",
    "    \n",
    "    # compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "    #classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "    classifier = torch.load(modelname)\n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    classifier.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    return train_state['test_loss'],  train_state['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6bd729f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name, model):\n",
    "    torch.save(model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cce14ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = test(\"CNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e2320c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5631030996640524;\n",
      "Test Accuracy: 73.69791666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(loss))\n",
    "print(\"Test Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2e95cf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsClassifier(\n",
       "  (emb): Embedding(135, 100, padding_idx=0)\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (7): ELU(alpha=1.0)\n",
       "  )\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('CNN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4b4a51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5549281636873881;\n",
      "Test Accuracy: 73.4375\n"
     ]
    }
   ],
   "source": [
    "loss, acc = test(\"CNN.pt\")\n",
    "\n",
    "print(\"Test loss: {};\".format(loss))\n",
    "print(\"Test Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "87235660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsClassifier(\n",
       "  (emb): Embedding(135, 100, padding_idx=0)\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (7): ELU(alpha=1.0)\n",
       "  )\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('CNN1.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2ae20d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5390400489171346;\n",
      "Test Accuracy: 74.73958333333333\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = test(\"CNN1.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss1))\n",
    "print(\"Test Accuracy: {}\".format(acc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace74ac",
   "metadata": {},
   "source": [
    "#### We have made 3 models for this task so far\n",
    "1. A feed-forward neural network model with one hot word embedding, learing rate (0.003)\n",
    "2. A CNN model with glove 100d pre-trained word embedding, learing rate (0.001),  dropout (0.1)\n",
    "3. A CNN model with glove 100d pre-trained word embedding, learing rate (0.001), dropout (0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2bc46",
   "metadata": {},
   "source": [
    "##### 1. Load FFN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "297efcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryClassifier(\n",
       "  (fc1): Linear(in_features=238, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('FFN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d15c56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.681\n",
      "Test Accuracy: 72.14\n"
     ]
    }
   ],
   "source": [
    "loss_ffn1, acc_ffn1 = test_ffn(\"FFN.pt\", args)\n",
    "print(\"Test loss: {:.3f}\".format(loss_ffn1))\n",
    "print(\"Test Accuracy: {:.2f}\".format(acc_ffn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb056db",
   "metadata": {},
   "source": [
    "##### 2. Load CNN model with learning rate 0.001 and dropout 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e628d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsClassifier(\n",
       "  (emb): Embedding(135, 100, padding_idx=0)\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (7): ELU(alpha=1.0)\n",
       "  )\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('CNN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "33880b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.552660197019577;\n",
      "Test Accuracy: 73.4375\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = test(\"CNN.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss1))\n",
    "print(\"Test Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5bcc93",
   "metadata": {},
   "source": [
    "##### 3. Load CNN model with learning rate 0.001 and dropout 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f0e18467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsClassifier(\n",
       "  (emb): Embedding(135, 100, padding_idx=0)\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Conv1d(100, 100, kernel_size=(3,), stride=(2,))\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
       "    (7): ELU(alpha=1.0)\n",
       "  )\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('CNN1.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "33293498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5551626483599345;\n",
      "Test Accuracy: 74.47916666666667\n"
     ]
    }
   ],
   "source": [
    "loss_cnn1, acc_cnn1 = test(\"CNN1.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss_cnn1))\n",
    "print(\"Test Accuracy: {}\".format(acc_cnn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848432e8-7c04-403a-9f85-621e50691405",
   "metadata": {},
   "source": [
    "<b>Performance Analysis</b>\n",
    "\n",
    "The highest test accuracy in FFN model is 72.1, which is slightly lower than both CNN models with accuracy 73.4 and 74.5 respectively. That means CNN may more powrful than FFN in binary classification nlp task. Moreover, we use the pre-trained word embedding in CNN classifier, which may help the classifier to catch up more text feature. As a whole, these 3 models provides pretty close accuracy on test dataset. One of important reason that CNN did not critically increase the perfomance is probably because we have trained the model on small dataset. CNN usually need to be trained on larger dataset to obtain better performance. Also, CNN with glove is a more complex model compared to FFN, which means there are more hypyer-parameters to adujust before the training. In addition, a slight increase of dropout ratio in CNN may increase the model performance. The drop ratio used in the training process to reduce time consuming and avoid overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848a2ee-375c-4cd7-bea7-e6a412aa4566",
   "metadata": {},
   "source": [
    "## Task 2: Multi-class Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df58b30-36a8-4c59-8cfa-4b362af45a90",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "\n",
    "In this task, we use the simple RNN to train the classifier. The class <b>MultiVectorizer</b> is used to encode the narrative data into vectors, <b>Injury2Dataset</b> is the dataloader. <b>Injury2Classifier</b> is the model we use for training the document classifier. These classes are packed into the Models.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feeb572f-89a6-4c2c-b314-6d5274247d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dce95a2-8664-4bb9-9f6c-cf6e43c27cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    body_csv= \"C:/Users/George/CITS4012/final2.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"C:/Users/George/CITS4012\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=128,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=256,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ac3b39-7bad-4357-a7d8-1a0759ab612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = Injury2Dataset.load_dataset_and_load_vectorizer(args.body_csv, \n",
    "                                                              args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = Injury2Dataset.load_dataset_and_make_vectorizer(args.body_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = Injury2Classifier(embedding_size=args.char_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.NARRATIVE),\n",
    "                               num_classes=len(vectorizer.body_injury),\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.NARRATIVE.mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c88b32-b3eb-4da5-b62c-3f17f6a96d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injury2Classifier(\n",
      "  (emb): Embedding(31, 100, padding_idx=0)\n",
      "  (rnn): ElmanRNN(\n",
      "    (rnn_cell): RNNCell(100, 128)\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc0ff25-33c0-41af-b1cb-bcc0feaeb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "\n",
    "    return torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11ec76f-fae1-45d0-850c-136ca358b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eacb1ca4-c35b-4082-9278-fbefca0c9b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6372fa45e54450798102f498ed49e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1478a4e48eb4a53a8738086273f9223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fa21b38479414ab7a4cd7eda225a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b2810b9-53a6-49d6-82d2-8fa02e74f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier, \"RNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe865fa-51ac-45fa-8097-74f35a2e814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(modelname, args):\n",
    "    model = torch.load(modelname)\n",
    "    model = model.to(args.device)\n",
    "    train_state = make_train_state(args)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred =  model(batch_dict['x_data'],\n",
    "                             x_lengths=batch_dict['x_length'])\n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    \n",
    "    return  train_state['test_loss'], train_state['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4436f6df-3ce7-4fdd-9227-4f077b483425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Injury2Classifier(\n",
       "  (emb): Embedding(31, 100, padding_idx=0)\n",
       "  (rnn): ElmanRNN(\n",
       "    (rnn_cell): RNNCell(100, 128)\n",
       "  )\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn = torch.load(\"RNN.pt\")\n",
    "model_rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae4bfbc-a124-494c-8e7b-a1d483161924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.10857355594635;\n",
      "Test Accuracy: 34.765625\n"
     ]
    }
   ],
   "source": [
    "loss, acc = test(\"RNN.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss))\n",
    "print(\"Test Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd93bd-30b7-405e-9e52-fa4b34aeac58",
   "metadata": {},
   "source": [
    "#### GRU\n",
    "\n",
    "In this part, we use the bi-GRU to train the classifier instead of a simple RNN. As well known, rnn is a model with short-term memory. When dealing with the long sequence samples, rnn may forget the previous semantic features and become struggle to learn. Thus, using the bi-GRU model can help to memorise the further semantic feature of the sequence sample. Moreover, we apply the pre-trained word embedding to improve the model accuracy.\n",
    "\n",
    "The class <b>MultiVectorizer</b> is used to encode the narrative data into vectors, <b>Injury2Dataset</b> is the dataloader. <b>InjuryGRUClassifier</b> is the model we use for training the document classifier. These classes are packed into the Models.py. Besides, we make the pre-trained word embedding matrix by a method called \"make_embedding_matrix()\" that is packed in the helper.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767e2ccf-dc52-4897-8396-f3d69dfc06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e399a2-6c25-457f-8be4-868f84598f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    body_csv=\"C:/Users/George/CITS4012/final2.csv\",\n",
    "    vectorizer_file=\"vectorizer_LS_1.json\",\n",
    "    model_state_file=\"model_LS_1.pth\",\n",
    "    save_dir=\"C:/Users/George/CITS4012\",\n",
    "    glove_filepath=\"C:/Users/George/CITS4012/glove/glove.6B.100d.txt\", \n",
    "    use_glove=False,\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=128,\n",
    "    bidirection = True,\n",
    "    n_layer = 1,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=80,\n",
    "    learning_rate=0.006,\n",
    "    batch_size=128,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=10,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef212c82-4444-4ea7-b878-70155faef411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the word embedding\n",
    "args.use_glove = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a9d1c1-f5a1-4f01-bfcd-3bd76c8c2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = Injury2Dataset.load_dataset_and_load_vectorizer(args.body_csv, \n",
    "                                                              args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = Injury2Dataset.load_dataset_and_make_vectorizer(args.body_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27e715-82c5-477b-917a-5668b8e24256",
   "metadata": {},
   "source": [
    "Set the argument \"args.use_glove\" is true means we want to use glove as pre-trained word embedding. Then, we load the glove file and make the embedding matrix by make_embedding_matrix(), this method is packed into the helpers.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84699e4b-c27e-4807-a659-d7bc338c8d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained embeddings\n"
     ]
    }
   ],
   "source": [
    "# Use GloVe or randomly initialized embeddings\n",
    "if args.use_glove:\n",
    "    words = vectorizer.NARRATIVE._token_to_idx.keys()\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83694936-e0c9-4d18-952f-a76f6363e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20555636, -0.00213669,  0.06000623, ...,  0.05345052,\n",
       "        -0.21676874,  0.12614274],\n",
       "       [-0.23994221,  0.22909459, -0.13612111, ..., -0.01033159,\n",
       "        -0.19344293, -0.16833046],\n",
       "       [-0.23632628,  0.1060884 , -0.20055968, ...,  0.18710664,\n",
       "        -0.03777884, -0.15639886],\n",
       "       ...,\n",
       "       [-0.69182   ,  0.47268   ,  0.41292   , ..., -0.29114   ,\n",
       "         0.081476  , -1.4222    ],\n",
       "       [-0.55668   ,  0.67273   ,  0.82171   , ..., -0.7515    ,\n",
       "        -0.045485  , -0.12946   ],\n",
       "       [-0.0049027 ,  0.21282   ,  0.27713   , ..., -0.72202   ,\n",
       "        -0.22217   , -0.71125   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390bc5b-8880-4ce7-8cac-c1cc053eb53f",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584e871-5a44-4f15-b302-a7d78435a930",
   "metadata": {},
   "source": [
    "The default RNN model is GRU, but we can change the argument \"rnn_model\" to LSTM if we want to train with LSTM. And we pass the pre-trained word embedding to our GRU classifier. If don't use the pre-trained word embedding, the argument \"embedding_tensor\" should be set to \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c43c8cb-b7cc-4113-b643-9e154b30f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InjuryGRUClassifier(vocab_size=len(vectorizer.NARRATIVE),\n",
    "                               embed_size=args.char_embedding_size,\n",
    "                               num_output=len(vectorizer.body_injury),\n",
    "                               rnn_model='GRU',\n",
    "                               embedding_tensor= embeddings,\n",
    "                               hidden_size=args.rnn_hidden_size,\n",
    "                               num_layers=args.n_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6616d6-1c89-41a5-83ed-d56d205da29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ddbefd4-af98-4e40-a289-7f4e442d13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fec77ba-43c4-4cc0-8ef4-caae3c5175f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sava the whole trained model\n",
    "torch.save(model, \"BiGRU_WORD_EMD.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06f528-d18d-4767-b067-c98e64533e0c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d816ef5-26ec-4c2b-bb5e-d80633f31e8b",
   "metadata": {},
   "source": [
    "We make the test routine as a function so that we can compare the model accuracy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2e89620-465c-4736-86b7-d4f0a8b2c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "def test(modelname, args):\n",
    "    model = torch.load(modelname)\n",
    "    model = model.to(args.device)\n",
    "    train_state = make_train_state(args)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred =  model(batch_dict['x_data'],\n",
    "                             x_lengths=batch_dict['x_length'])\n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    \n",
    "    return  train_state['test_loss'], train_state['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db823115-9abd-4801-84e1-6e81ff7a2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8817292749881744;\n",
      "Test Accuracy: 64.84375\n"
     ]
    }
   ],
   "source": [
    "loss, acc = test(\"BiGRU_WORD_EMD.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss))\n",
    "print(\"Test Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a1909-dae8-4c53-92d4-b2ae87aa1f27",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828037a-2823-423e-b878-627fff45b28d",
   "metadata": {},
   "source": [
    "We have attempted multiple experiments to adjust the hyper-parameters aiming at improving the test accuracy. We have made 5 models so far, which are:\n",
    "1. A simple RNN model with no pre-trained word embedding, learing rate (0.001), layers(1), dropout (0.5)\n",
    "2. A bi-GRU model with no pre-trained word embedding, learing rate (0.001), layers(1), dropout (0.2)\n",
    "3. A bi-GRU model with no pre-trained word embedding, learing rate (0.006), layers(2), dropout (0.2)\n",
    "4. A bi-GRU model with pre-trained word embedding, learing rate (0.005), layers(2), dropout (0.2)\n",
    "5. A bi-GRU model with pre-trained word embedding, learing rate (0.006), layers(1), dropout (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14750d7-f92a-42b7-a602-6020215cdd47",
   "metadata": {},
   "source": [
    "##### 1. Load trained RNN model without pre-trained word embedding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db6efc67-11c4-432e-be1a-3e2e6366e351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Injury2Classifier(\n",
       "  (emb): Embedding(31, 100, padding_idx=0)\n",
       "  (rnn): ElmanRNN(\n",
       "    (rnn_cell): RNNCell(100, 128)\n",
       "  )\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn = torch.load(\"RNN.pt\")\n",
    "model_rnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc2509-62e2-478e-95b7-1e759ed12414",
   "metadata": {},
   "source": [
    "##### The test accuracy of RNN model is around 33%, which is slightly better than random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d19f141e-f7d1-4e45-ae51-b00107efc839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1197128295898438;\n",
      "Test Accuracy: 33.984375\n"
     ]
    }
   ],
   "source": [
    "loss0, acc0 = test(\"RNN.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss0))\n",
    "print(\"Test Accuracy: {}\".format(acc0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f320d6e-5163-40f9-a626-d4afcf57411d",
   "metadata": {},
   "source": [
    "##### 2. Load the first bi-GRU model using default learning rate (0.001), dropout(0.2) and layers (1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4acbbc6-11f7-439b-91f8-98157de94e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryGRUClassifier(\n",
       "  (encoder): Embedding(31, 100, padding_idx=0)\n",
       "  (drop_en): Dropout(p=0.6, inplace=False)\n",
       "  (rnn): GRU(100, 128, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru_default = torch.load(\"BiGRU_0.01.pt\")\n",
    "model_gru_default.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c80694-0b7b-40b4-bcd2-2023bf439c25",
   "metadata": {},
   "source": [
    "##### With using the bi-GRU model, the test accuracy is improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "391f8d3c-eb0a-468c-a2c0-b51a5875b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1019163131713867;\n",
      "Test Accuracy: 38.671875\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = test(\"BiGRU_0.01.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss1))\n",
    "print(\"Test Accuracy: {}\".format(acc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5fc83-301c-425c-9820-691ed2384318",
   "metadata": {},
   "source": [
    "##### 3. Load the bi-GRU without pre-trainning word embedding, adjusting layers as 2, dropout as 0.3 and learning rate as 0.006 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa594fcb-efb8-4d4d-9361-590422d9a964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryGRUClassifier(\n",
       "  (encoder): Embedding(31, 100, padding_idx=0)\n",
       "  (drop_en): Dropout(p=0.6, inplace=False)\n",
       "  (rnn): GRU(100, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_emd = torch.load(\"BiGRU_50.pt\")\n",
    "model_no_emd.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d745116-5389-491d-a0d0-9737d2cd808e",
   "metadata": {},
   "source": [
    "##### The test accuracy is between 46% to 50% after multiple experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f762d49-36fe-449b-bc0a-38ec8998b93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0334081649780273;\n",
      "Test Accuracy: 48.4375\n"
     ]
    }
   ],
   "source": [
    "loss2, acc2 = test(\"BiGRU_50.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss2))\n",
    "print(\"Test Accuracy: {}\".format(acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30b230-02ab-40ce-af90-b13049ee4e65",
   "metadata": {},
   "source": [
    "##### 4. This model is trained by bi-GRU using glove as pretained word embedding, with 2 layer, 0.05 learning rate and 0.2 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbac226f-1ae5-43e0-9404-f20a2dfb7652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryGRUClassifier(\n",
       "  (encoder): Embedding(31, 100, padding_idx=0)\n",
       "  (drop_en): Dropout(p=0.6, inplace=False)\n",
       "  (rnn): GRU(100, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru1 = torch.load(\"BiGRU_60.pt\")\n",
    "model_gru1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49395cfe-9ea6-4725-8be7-28f77f5e7e22",
   "metadata": {},
   "source": [
    "##### The test accuracy is around 60%, which is about 10% higher than model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d81fcc-6e23-44fa-a698-8e4d2aaad532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8685162365436554;\n",
      "Test Accuracy: 60.546875\n"
     ]
    }
   ],
   "source": [
    "loss3, acc3 = test(\"BiGRU_60.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss3))\n",
    "print(\"Test Accuracy: {}\".format(acc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e6f49-fe87-4619-bcb4-89c7d695fe9c",
   "metadata": {},
   "source": [
    "##### 5. This is the best bi-GRU model we have trained so far, with 1 layer, 0.3 dropout and 0.06 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df05b661-2970-4318-9fea-241cf0ce0064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjuryGRUClassifier(\n",
       "  (encoder): Embedding(31, 100, padding_idx=0)\n",
       "  (drop_en): Dropout(p=0.6, inplace=False)\n",
       "  (rnn): GRU(100, 128, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru2 = torch.load(\"BiGRU_WORD_EMD.pt\")\n",
    "model_gru2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252b1a3-199b-4889-8c6a-2ee903e6fadb",
   "metadata": {},
   "source": [
    "##### The test accuracy is around 66% in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b17c3510-eaab-4c4f-ba8d-123346e6f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8887283504009247;\n",
      "Test Accuracy: 66.015625\n"
     ]
    }
   ],
   "source": [
    "loss4, acc4 = test(\"BiGRU_WORD_EMD.pt\", args)\n",
    "\n",
    "print(\"Test loss: {};\".format(loss4))\n",
    "print(\"Test Accuracy: {}\".format(acc4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1c033-cb60-455f-b506-3ee2d574b827",
   "metadata": {},
   "source": [
    "<b>Performance Analysis</b>\n",
    "\n",
    "To summerise, the single RNN without any hyper-parameters adjusting can achieve around 33% to 36% accuracy, which is slightly better than the random guess. By using the bi-GRU model without any hyper-parameters adjusting, the model can achieve around 38% to 40% accuracy, which shows better performance than using the RNN. In the third model, we increase the learning rate as 6 times larger as the second model (from 0.01 to 0.06), lower the GRU dropout from 0.5 to 0.3, and add one more layer. This adjustment slighly improves the model accuracy by 6% approximately. \n",
    "\n",
    "The improvement for the third model is mainly because we significantly increase learning rate. Since we train the classifier on small dataset (each class only has about 580 samples), small learning rate will slow down the process of gradient descent so that the model cannot reach the local optima. By conducting multiple experiments, we find the best learning rate for this model is 0.005 and 0.006. The accuracy goes down once the learning rate is over than 0.06.\n",
    "\n",
    "In the 4th model, we apply the pre-trained word embedding to train the model, and it turns out be a successful idea because the test accuracy is increase to 60%. The advantage of using pre-training is that it can speed up the training of the model and alleviate the problem of insufficient training data. Because the pre-training word embedding can help the classifier better understand the semantic features. And the last model just slightly modify some hyper-parameters such as number of layers, and it is the best model we have trained so far, with the accuracy of 66%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1a78c-0f31-4d53-bbb5-7209ca203977",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "This task is presented by two part, part1 we do the data pre-processing, and part 2 we build the models and evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a765cc-14ab-4415-83dc-9664669c6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30fd92a-3a90-4362-854a-71f8bcfb86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c412b3-91a2-403b-807f-261543221fc2",
   "metadata": {},
   "source": [
    "<b>1. Sequence Data Pre-processing</b>\n",
    "\n",
    "Before building the model for this task, we conduct the data pre-processing first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4002407d-1734-4380-8761-d5820ddf351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    source_data_path=\"C:/Users/George/CITS4012/us_accidents.txt\",\n",
    "    output_data_path=\"C:/Users/George/CITS4012/us_accidents_out.csv\",\n",
    "    perc_train=0.7,\n",
    "    perc_val=0.15,\n",
    "    perc_test=0.15,\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "assert args.perc_test > 0 and (args.perc_test + args.perc_val + args.perc_train == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2440258-11d0-47c8-bb9f-ede867665c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(args.source_data_path, encoding=\"utf-8\", errors = 'ignore') as fp:\n",
    "    lines = fp.readlines()\n",
    "    \n",
    "lines = [line.replace(\"\\n\", \"\").lower().split(\" \") for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c8613-99d6-4926-8c57-5b51a23c7a08",
   "metadata": {},
   "source": [
    "The sequence data is read into the buffer called \"lines\", each line inclues a word with its entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6e7f08-a042-46b6-9670-167e454a6c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'o'], ['was', 'o'], ['pulling', 'o'], ['a', 'o'], ['54', 'o']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e39b8-296b-4c33-9603-a27b0925df27",
   "metadata": {},
   "source": [
    "Pack each sentence and their entity to a dict, append it into another buffer called \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909af8e0-7fe3-4ee2-93ac-1e2ad9ea6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "ents = []\n",
    "data = []\n",
    "for i in lines:\n",
    "    if len(i) != 1:\n",
    "        words.append(i[0])\n",
    "        ents.append(i[1])\n",
    "    else:\n",
    "        data.append({\"words\" : words, \"ents\" : ents})\n",
    "        words=[]\n",
    "        ents=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51a678-b9bc-4c34-b923-dd8eda48cce5",
   "metadata": {},
   "source": [
    "We make a statistic to visulise the times of different entities exists accross the dataset, and we find the entity 'o' represent 90% of the entity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be9472e-261d-440a-a5f4-223023efdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the entities into ents\n",
    "ents = [ent['ents'][i] for ent in data for i in range(len(ent['ents']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee19e6c-9dba-4548-a790-3262ab8cf101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420603"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ba5a61-68d5-4e98-9c93-03ae0176e5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o                        378976\n",
       "b-person/employee         11420\n",
       "b-accident_cause/fall      2692\n",
       "                           1950\n",
       "b-body_part/back           1667\n",
       "                          ...  \n",
       "fibula                        1\n",
       "months                        1\n",
       "one                           1\n",
       "window                        1\n",
       "line/miner                    1\n",
       "Length: 858, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.value_counts(ents)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5eb4202-f62f-4a2f-889a-816d0636802f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010301876115957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the percentage of 'o'\n",
    "378976/len(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4850253-5b28-4858-9452-e2df81bf78eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41627"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the length of other entities except 'o'\n",
    "len(ents) - 378976"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9098be-b523-43a2-9733-d2db42f84ad8",
   "metadata": {},
   "source": [
    "Error checking for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7789f1c1-41be-4d8d-9fac-f520d0e62686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No error'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if all the sentence len and entities lenght are same\n",
    "def check():\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]['words']) != len(data[i]['ents']):\n",
    "            return (\"sentence i {} has error !\".format(i))\n",
    "    return 'No error'\n",
    "\n",
    "check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88e37d-a843-4e61-aa0b-db3b05e48457",
   "metadata": {},
   "source": [
    "Split the data into train (70%), validation (15%), and test (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5efb7346-d190-412c-ab56-d78527a2300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(data) * args.perc_train)\n",
    "n_val = int(len(data) * args.perc_val)\n",
    "dataset= []\n",
    "for datum in data[:n_train]:\n",
    "    datum['split'] = 'train'\n",
    "\n",
    "    \n",
    "for datum in data[n_train:n_train+n_val]:\n",
    "    datum['split'] = 'val'\n",
    "\n",
    "for datum in data[n_train+n_val:]:\n",
    "    datum['split'] = 'test'\n",
    "\n",
    "dataset.extend(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef27013-f27a-415b-a1f4-d68d425f01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we pop and assign into the dictionary, thus modifying in place\n",
    "for datum in dataset:\n",
    "    datum['words'] = \" \".join(datum.pop('words'))\n",
    "    datum['ents'] = \" \".join(datum.pop('ents'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19f7df16-373b-487b-8836-51490c6e6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed04dfd4-1236-47a8-9192-fd6c5796ddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>words</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>he was pulling a 54 inch v wiper and felt pain...</td>\n",
       "      <td>o o o o o o o o o o o o o o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>breathing difficulties . employee provided fir...</td>\n",
       "      <td>o o o b-person/employee o o o o o o o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>while palletizing flat rock ( landscape stone ...</td>\n",
       "      <td>o o o o o o o o b-person/injured_person i-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>employee was helping load bolts on roof bolter...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>employee stepped into hot feed and fell while ...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split                                              words  \\\n",
       "0  train  he was pulling a 54 inch v wiper and felt pain...   \n",
       "1  train  breathing difficulties . employee provided fir...   \n",
       "2  train  while palletizing flat rock ( landscape stone ...   \n",
       "3  train  employee was helping load bolts on roof bolter...   \n",
       "4  train  employee stepped into hot feed and fell while ...   \n",
       "\n",
       "                                                ents  \n",
       "0                      o o o o o o o o o o o o o o o  \n",
       "1            o o o b-person/employee o o o o o o o o  \n",
       "2  o o o o o o o o b-person/injured_person i-pers...  \n",
       "3  b-person/employee o o o o o o o o o o o o o o ...  \n",
       "4        b-person/employee o o o o o o o o o o o o o  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf795f5b-06c5-4fcb-8578-068d4af3fbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>words</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>he was pulling a 54 inch v wiper and felt pain...</td>\n",
       "      <td>o o o o o o o o o o o o o o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>breathing difficulties . employee provided fir...</td>\n",
       "      <td>o o o b-person/employee o o o o o o o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>while palletizing flat rock ( landscape stone ...</td>\n",
       "      <td>o o o o o o o o b-person/injured_person i-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>employee was helping load bolts on roof bolter...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>employee stepped into hot feed and fell while ...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>train</td>\n",
       "      <td>employee was adjusting packing on booster pump...</td>\n",
       "      <td>b-person/employee o o o o o b-equipment/mechan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>train</td>\n",
       "      <td>while crawling over post pile on pillar sectio...</td>\n",
       "      <td>o o o o o o o o o o b-body_part/arm/hand o o o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>train</td>\n",
       "      <td>employee was working on a rotary diverter when...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o b-body_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>train</td>\n",
       "      <td>employee was chipping out build up inside of c...</td>\n",
       "      <td>b-person/employee o o o o o o o o b-equipment/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>train</td>\n",
       "      <td>employee had been stripping using a dozer . wh...</td>\n",
       "      <td>b-person/employee o o o o o b-vehicle/heavy_ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      split                                              words  \\\n",
       "0     train  he was pulling a 54 inch v wiper and felt pain...   \n",
       "1     train  breathing difficulties . employee provided fir...   \n",
       "2     train  while palletizing flat rock ( landscape stone ...   \n",
       "3     train  employee was helping load bolts on roof bolter...   \n",
       "4     train  employee stepped into hot feed and fell while ...   \n",
       "...     ...                                                ...   \n",
       "6995  train  employee was adjusting packing on booster pump...   \n",
       "6996  train  while crawling over post pile on pillar sectio...   \n",
       "6997  train  employee was working on a rotary diverter when...   \n",
       "6998  train  employee was chipping out build up inside of c...   \n",
       "6999  train  employee had been stripping using a dozer . wh...   \n",
       "\n",
       "                                                   ents  \n",
       "0                         o o o o o o o o o o o o o o o  \n",
       "1               o o o b-person/employee o o o o o o o o  \n",
       "2     o o o o o o o o b-person/injured_person i-pers...  \n",
       "3     b-person/employee o o o o o o o o o o o o o o ...  \n",
       "4           b-person/employee o o o o o o o o o o o o o  \n",
       "...                                                 ...  \n",
       "6995  b-person/employee o o o o o b-equipment/mechan...  \n",
       "6996  o o o o o o o o o o b-body_part/arm/hand o o o...  \n",
       "6997  b-person/employee o o o o o o o o o o b-body_p...  \n",
       "6998  b-person/employee o o o o o o o o b-equipment/...  \n",
       "6999  b-person/employee o o o o o b-vehicle/heavy_ve...  \n",
       "\n",
       "[7000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out train dataset, from 0 to 6999\n",
    "df[df['split'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb1f81d9-7529-4fa6-8ee5-3128d6f708b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>words</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>val</td>\n",
       "      <td>a sight string was hung from the roof screens ...</td>\n",
       "      <td>o o o o o o o o o o o o o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>val</td>\n",
       "      <td>employee reported that he pushed the wrong lev...</td>\n",
       "      <td>b-person/employee o o o o o o raising o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>val</td>\n",
       "      <td>while exiting number 1 clinker cooler during r...</td>\n",
       "      <td>o o o o o o o o o o o o o o o b-person/employe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>val</td>\n",
       "      <td>the employee was using a hammer to clear clog ...</td>\n",
       "      <td>o b-person/employee o o o o o o o o b-equipmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>val</td>\n",
       "      <td>roof fall &amp;gt; e-mains number 15 block in numb...</td>\n",
       "      <td>o b-accident_cause/fall o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>val</td>\n",
       "      <td>roof fall old room set up in number 4 entry on...</td>\n",
       "      <td>o b-accident_cause/fall o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>val</td>\n",
       "      <td>employee was shooting a klinker out of the num...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>val</td>\n",
       "      <td>employee stated that strained his back while l...</td>\n",
       "      <td>b-person/employee o o o o b-body_part/back o o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>val</td>\n",
       "      <td>employee was cleaning up in the hydrate bag ar...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>val</td>\n",
       "      <td>employee was removing 3 '' water that was hook...</td>\n",
       "      <td>b-person/employee o o o o line o o o o o o o o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     split                                              words  \\\n",
       "7000   val  a sight string was hung from the roof screens ...   \n",
       "7001   val  employee reported that he pushed the wrong lev...   \n",
       "7002   val  while exiting number 1 clinker cooler during r...   \n",
       "7003   val  the employee was using a hammer to clear clog ...   \n",
       "7004   val  roof fall &gt; e-mains number 15 block in numb...   \n",
       "...    ...                                                ...   \n",
       "8495   val  roof fall old room set up in number 4 entry on...   \n",
       "8496   val  employee was shooting a klinker out of the num...   \n",
       "8497   val  employee stated that strained his back while l...   \n",
       "8498   val  employee was cleaning up in the hydrate bag ar...   \n",
       "8499   val  employee was removing 3 '' water that was hook...   \n",
       "\n",
       "                                                   ents  \n",
       "7000  o o o o o o o o o o o o o o o o o o o o o o o ...  \n",
       "7001  b-person/employee o o o o o o raising o o o o ...  \n",
       "7002  o o o o o o o o o o o o o o o b-person/employe...  \n",
       "7003  o b-person/employee o o o o o o o o b-equipmen...  \n",
       "7004  o b-accident_cause/fall o o o o o o o o o o o ...  \n",
       "...                                                 ...  \n",
       "8495  o b-accident_cause/fall o o o o o o o o o o o ...  \n",
       "8496  b-person/employee o o o o o o o o o o o o o o ...  \n",
       "8497  b-person/employee o o o o b-body_part/back o o...  \n",
       "8498  b-person/employee o o o o o o o o o o o o o o ...  \n",
       "8499  b-person/employee o o o o line o o o o o o o o...  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out validation dataset, from 7000 to 8499\n",
    "df[df['split'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3ad8eeb-f95c-4097-b350-989824cccf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>words</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8500</th>\n",
       "      <td>test</td>\n",
       "      <td>employee was driving tractor trailer . the roa...</td>\n",
       "      <td>b-person/employee o b-activity/driving o o o o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8501</th>\n",
       "      <td>test</td>\n",
       "      <td>employee was changing out a pump when the shaf...</td>\n",
       "      <td>b-person/employee o o o o b-equipment/mechanic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502</th>\n",
       "      <td>test</td>\n",
       "      <td>during an inspection of the hart street elevat...</td>\n",
       "      <td>o o o o o o o o o safety o o o o o o o o o o o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8503</th>\n",
       "      <td>test</td>\n",
       "      <td>while cleaning along side screening plant , a ...</td>\n",
       "      <td>o o o o o o o o o o o o o o o b-body_part/head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>test</td>\n",
       "      <td>employee was dismounting a mantrip , while get...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o o b-bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>test</td>\n",
       "      <td>climbing upon the grader and felt his back pop...</td>\n",
       "      <td>o o o b-vehicle/heavy_vehicle/grader o o o b-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>test</td>\n",
       "      <td>fell from rock bin . shirt caught on guard , l...</td>\n",
       "      <td>o o o o o o o o o o o o o o o o o o o b-body_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>test</td>\n",
       "      <td>employee was lifting tank of oxygen at supply ...</td>\n",
       "      <td>b-person/employee o o o o o o o o o o o b-body...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>test</td>\n",
       "      <td>employee was picking up his chock blocks when ...</td>\n",
       "      <td>b-person/employee o o o o b-equipment/chock o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>test</td>\n",
       "      <td>supervisor stated employee complained of a sor...</td>\n",
       "      <td>b-person/supervisor o b-person/employee o o o ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     split                                              words  \\\n",
       "8500  test  employee was driving tractor trailer . the roa...   \n",
       "8501  test  employee was changing out a pump when the shaf...   \n",
       "8502  test  during an inspection of the hart street elevat...   \n",
       "8503  test  while cleaning along side screening plant , a ...   \n",
       "8504  test  employee was dismounting a mantrip , while get...   \n",
       "...    ...                                                ...   \n",
       "9995  test  climbing upon the grader and felt his back pop...   \n",
       "9996  test  fell from rock bin . shirt caught on guard , l...   \n",
       "9997  test  employee was lifting tank of oxygen at supply ...   \n",
       "9998  test  employee was picking up his chock blocks when ...   \n",
       "9999  test  supervisor stated employee complained of a sor...   \n",
       "\n",
       "                                                   ents  \n",
       "8500  b-person/employee o b-activity/driving o o o o...  \n",
       "8501  b-person/employee o o o o b-equipment/mechanic...  \n",
       "8502  o o o o o o o o o safety o o o o o o o o o o o...  \n",
       "8503  o o o o o o o o o o o o o o o b-body_part/head...  \n",
       "8504  b-person/employee o o o o o o o o o o o o b-bo...  \n",
       "...                                                 ...  \n",
       "9995  o o o b-vehicle/heavy_vehicle/grader o o o b-b...  \n",
       "9996  o o o o o o o o o o o o o o o o o o o b-body_p...  \n",
       "9997  b-person/employee o o o o o o o o o o o b-body...  \n",
       "9998  b-person/employee o o o o b-equipment/chock o ...  \n",
       "9999  b-person/supervisor o b-person/employee o o o ...  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out test dataset, from 8500 to 9999\n",
    "df[df['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab4327aa-1841-43c1-b179-9281b16bfe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "588e3d50-4579-4646-a59c-60ff39d0363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to csv file\n",
    "#df.to_csv(args.output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29b8a9-6643-4965-9582-c390cdd56271",
   "metadata": {},
   "source": [
    "<b>2. Bi-GRU with Attention to train the seq2seq model<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19fd4f7b-1af6-4b37-a5c6-64c101989934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c311c1-eed3-4bcb-a2f8-79fc3983c391",
   "metadata": {},
   "source": [
    "<b>Our seq2seq model : </b>\n",
    "\n",
    "For the task 2, we have used the bi-GRU to train the multi-classfier and has achieved a satisfying result. In this task, we continue to use the bi-GRU method with attention to train a seq2seq model. The advantage of using the bi-GRU rather than the normal GRU is that bi-GRU has longer memory than the GRU, beacuse bi-GRU starts from left to right and right to left, which helps to memorise the eariler text feature when the sequence is long. Moreover, attention method is introduced to enhance the model performance by getting better feature information of the source input. \n",
    "\n",
    "We use a bi-GRU method for the encoder, and use a normal GRU method for the decoder since the decoder is a text generator that need to generate the sequence text in order. The training process of our seq2seq model can be summerised as the follows:\n",
    "\n",
    "1. The encoder that applied bi-GRU summerise the text feature into the last hidden state h(m), and this hidden state is the initial state for decoder, denote as s(0). \n",
    "2. Attention method calculates the weight for all the hidden states from the encoder, and each weight w(i) represents the correlation between the hidden states {h(0), h(1), ... h(m)} and s(0).\n",
    "3. Attention method calculates the context vector c(0), which is the weighted sum average of hidden states {h(0), h(1), ... h(m)} and weights {w(0), w(1), .... w(m)}.\n",
    "4. Decoder combines the context vector c(0), the hidden state s(0) and the input text x(0) to generate the next hidden state s(1).\n",
    "5. By iteratively using the encoder, attention and decoder. The model can generate a predicted sequence. \n",
    "6. Compares the label sequence with the predicted sequence to obtain the loss and gradient information, then backpropogate to update the decoder and encoder.\n",
    "7. Repeat 1 to 6 for the next sequence until the training process is finised.\n",
    "\n",
    "We incorporate the code from lab 12 to finish this task. The model is defined as NMTModel and made up by NMTEncoder and NMTSamDecoder. The attention calculation for the model is performed in the NMTSamDecoder. At the end of the notebook, we will evaluate the models by calculating the percentage of disagreements on test dataset.\n",
    "\n",
    "<b>NMTEncoder</b>, <b>NMTSamDecoder</b> and <b>NMTModel</b> are encapsulated in the \"Model.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5cb2b6-4f57-43a1-a646-d2d51b1c0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nmt_batches(dataset, batch_size, shuffle=True, \n",
    "                            drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"A generator function which wraps the PyTorch DataLoader.  The NMT Version \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        lengths = data_dict['x_source_length'].numpy()\n",
    "        # Get the indices according to sorted length\n",
    "        sorted_length_indices = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        # Sort the minibatch\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa31cdd-8e4c-4618-84b3-fd936e560812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose_attention(encoder_state_vectors, query_vector):\n",
    "    \"\"\"A descriptive version of the neural attention mechanism \n",
    "    \n",
    "    Args:\n",
    "        encoder_state_vectors (torch.Tensor): 3dim tensor from bi-GRU in encoder\n",
    "        query_vector (torch.Tensor): hidden state in decoder GRU\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    batch_size, num_vectors, vector_size = encoder_state_vectors.size()\n",
    "    vector_scores = torch.sum(encoder_state_vectors * query_vector.view(batch_size, 1, vector_size), \n",
    "                              dim=2)\n",
    "    vector_probabilities = F.softmax(vector_scores, dim=1)\n",
    "    weighted_vectors = encoder_state_vectors * vector_probabilities.view(batch_size, num_vectors, 1)\n",
    "    context_vectors = torch.sum(weighted_vectors, dim=1)\n",
    "    return context_vectors, vector_probabilities, vector_scores\n",
    "\n",
    "def terse_attention(encoder_state_vectors, query_vector):\n",
    "    \"\"\"A shorter and more optimized version of the neural attention mechanism\n",
    "    \n",
    "    Args:\n",
    "        encoder_state_vectors (torch.Tensor): 3dim tensor from bi-GRU in encoder\n",
    "        query_vector (torch.Tensor): hidden state\n",
    "    \"\"\"\n",
    "    vector_scores = torch.matmul(encoder_state_vectors, query_vector.unsqueeze(dim=2)).squeeze()\n",
    "    vector_probabilities = F.softmax(vector_scores, dim=-1)\n",
    "    context_vectors = torch.matmul(encoder_state_vectors.transpose(-2, -1), \n",
    "                                   vector_probabilities.unsqueeze(dim=2)).squeeze()\n",
    "    return context_vectors, vector_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459c3938-b8d0-4156-81fb-7549fb782cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741011b1-86bb-48e8-9bbc-438f87db0130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5598bd63-aaff-4dd9-9bd1-9d9b6a014c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/sampling\\vectorizer.json\n",
      "\tmodel_storage/sampling\\model.pth\n",
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(dataset_csv=\"C:/Users/George/CITS4012/us_accidents_out.csv\",\n",
    "                 vectorizer_file=\"vectorizer.json\",\n",
    "                 model_state_file=\"model.pth\",\n",
    "                 #save_dir=\"model_storage/no_sampling\",\n",
    "                 save_dir=\"model_storage/sampling\",\n",
    "                 reload_from_files=True,\n",
    "                 expand_filepaths_to_save_dir=True,\n",
    "                 cuda=True,\n",
    "                 seed=1337,\n",
    "                 learning_rate=5e-4,\n",
    "                 batch_size=64,\n",
    "                 num_epochs=50,\n",
    "                 early_stopping_criteria=10,              \n",
    "                 source_embedding_size=64, \n",
    "                 target_embedding_size=64,\n",
    "                 encoding_size=64,\n",
    "                 catch_keyboard_interrupt=True)\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7046155a-d8e4-4e06-806a-a9008bda1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = NMTDataset.load_dataset_and_load_vectorizer(args.dataset_csv,\n",
    "                                                          args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd35211f-f665-4f76-b1e5-daa5f18ec496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model\n"
     ]
    }
   ],
   "source": [
    "model = NMTModel(source_vocab_size=len(vectorizer.source_vocab), \n",
    "                 source_embedding_size=args.source_embedding_size, \n",
    "                 target_vocab_size=len(vectorizer.target_vocab),\n",
    "                 target_embedding_size=args.target_embedding_size, \n",
    "                 encoding_size=args.encoding_size,\n",
    "                 target_bos_index=vectorizer.target_vocab.begin_seq_index)\n",
    "\n",
    "if args.reload_from_files and os.path.exists(args.model_state_file):\n",
    "    model.load_state_dict(torch.load(args.model_state_file))\n",
    "    print(\"Reloaded model\")\n",
    "else:\n",
    "    print(\"New model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f7b8a6-f045-4e19-a4ae-dff8e1273a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "mask_index = vectorizer.target_vocab.mask_index\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_nmt_batches(dataset, \n",
    "                                               batch_size=args.batch_size, \n",
    "                                               device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = model(batch_dict['x_source'], \n",
    "                           batch_dict['x_source_length'], \n",
    "                           batch_dict['x_target'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the running loss and running accuracy\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            \n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_nmt_batches(dataset, \n",
    "                                               batch_size=args.batch_size, \n",
    "                                               device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        model.eval()\n",
    "        try:\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # compute the output\n",
    "                y_pred = model(batch_dict['x_source'], \n",
    "                               batch_dict['x_source_length'], \n",
    "                               batch_dict['x_target'])\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "\n",
    "                # compute the running loss and accuracy\n",
    "                running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "                # Update bar\n",
    "                val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "                val_bar.update()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=model, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.set_postfix(best_val=train_state['early_stopping_best_val'] )\n",
    "        epoch_bar.update()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590406e2-9dc8-49f1-8ef9-89ecfd7bbcf1",
   "metadata": {},
   "source": [
    "<b>Inference and Evaluation</b>\n",
    "\n",
    "In this part, we present the result of model's performance testing. We first evaluate the model performance using \"Bleu\" method, then we evaluate the model's performance by analysing the disagreements on randomly picked 50 test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90400836-6979-4df3-a110-4e402a6a8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import bleu_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chencherry = bleu_score.SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e3a966b8-37a9-45e3-bd2b-765c4f05e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention_gru_v3.pt is our trained model\n",
    "model = torch.load(\"attention_gru_v3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "56f2841c-2d08-4181-886d-454ad5cdf420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_indices(indices, vocab, strict=True, return_string=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            break\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    if return_string:\n",
    "        return \" \".join(out)\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "class NMTSampler:\n",
    "    def __init__(self, vectorizer, model):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "    \n",
    "    def apply_to_batch(self, batch_dict):\n",
    "        self._last_batch = batch_dict\n",
    "        y_pred = self.model(x_source=batch_dict['x_source'], \n",
    "                            x_source_lengths=batch_dict['x_source_length'], \n",
    "                            target_sequence=batch_dict['x_target'])\n",
    "        self._last_batch['y_pred'] = y_pred\n",
    "        \n",
    "        attention_batched = np.stack(self.model.decoder._cached_p_attn).transpose(1, 0, 2)\n",
    "        self._last_batch['attention'] = attention_batched\n",
    "        \n",
    "    def _get_source_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch['x_source'][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.source_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "\n",
    "    def _get_reference_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch['y_target'][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "    \n",
    "    def _get_sampled_sentence(self, index, return_string=True):\n",
    "        _, all_indices = torch.max(self._last_batch['y_pred'], dim=2)\n",
    "        sentence_indices = all_indices[index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(sentence_indices, vocab, return_string=return_string)\n",
    "\n",
    "    def get_ith_item(self, index, return_string=True):\n",
    "        output = {\"source\": self._get_source_sentence(index, return_string=return_string), \n",
    "                  \"reference\": self._get_reference_sentence(index, return_string=return_string), \n",
    "                  \"sampled\": self._get_sampled_sentence(index, return_string=return_string),\n",
    "                  \"attention\": self._last_batch['attention'][index]}\n",
    "        \n",
    "        reference = output['reference']\n",
    "        hypothesis = output['sampled']\n",
    "        \n",
    "        if not return_string:\n",
    "            reference = \" \".join(reference)\n",
    "            hypothesis = \" \".join(hypothesis)\n",
    "        \n",
    "        output['bleu-4'] = bleu_score.sentence_bleu(references=[reference],\n",
    "                                                    hypothesis=hypothesis,\n",
    "                                                    smoothing_function=chencherry.method1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6c566f48-4226-475a-ad5e-bef4e8405477",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval().to(args.device)\n",
    "\n",
    "sampler = NMTSampler(vectorizer, model)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       device=args.device)\n",
    "batch_dict1 = next(batch_generator)\n",
    "test_results = []\n",
    "for batch_dict in batch_generator:\n",
    "    sampler.apply_to_batch(batch_dict)\n",
    "    for i in range(args.batch_size):\n",
    "        test_results.append(sampler.get_ith_item(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "257af97c-4b35-4ed3-99b9-32374ac09ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6333829518220855, 0.6299880123129222)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAN1ElEQVR4nO3dbYxc51nG8f9FkqqFFuLgtWUlXbYgUxohkpaljQigtiaQF4SD1KAWSK0qaIWgKEhI1PQDCPHFfEEVAlSsENUIaIlogk0LBcslBNQkrQN5xS0OIYQoVpykhZYigZzcfNjj4qx3M2d358zuM/v/SdbMOTOzcz/Z0bVP7nOeM6kqJEnt+bqNLkCStDYGuCQ1ygCXpEYZ4JLUKANckhp14STfbPv27TU3NzfJt5Sk5j3wwAPPV9XM0v0TDfC5uTmOHz8+ybeUpOYl+bfl9ttCkaRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY3qdRphkieBrwAvAmeqaj7JJcCfAHPAk8CPV9WXhilTkrTUambg76iqK6tqvtveDxyrqt3AsW5bkjQh62mh7AUOdfcPATeuuxpJUm99V2IW8NdJCvi9qjoI7KyqUwBVdSrJjuVemGQBWACYnZ0dQ8mStPnN7f/ky7afPHDD2N+jb4BfXVXPdCF9NMnn+75BF/YHAebn5/36H0kak14tlKp6prs9DdwFvBV4NskugO729FBFSpLONzLAk3xDktedvQ/8EPAocATY1z1tH3B4qCIlSefr00LZCdyV5Ozz/7iqPpXkc8AdSW4BngJuGq5MSdJSIwO8qp4Arlhm/wvAniGKkiSN5kpMSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIadeFGFyBtZnP7P/m1+08euGHT/CwJVjEDT3JBkn9M8olu+5IkR5Oc7G63DVemJGmp1bRQbgVOnLO9HzhWVbuBY922JGlCegV4ksuAG4Dbztm9FzjU3T8E3DjWyiRJr6jvDPxDwC8BL52zb2dVnQLobncs98IkC0mOJzn+3HPPradWSdI5RgZ4kh8BTlfVA2t5g6o6WFXzVTU/MzOzlh8hSVpGn7NQrgZ+NMn1wKuBb0zyh8CzSXZV1akku4DTQxYqSXq5kTPwqvrlqrqsquaAdwOfrqqfAo4A+7qn7QMOD1alJOk861nIcwC4JslJ4JpuW5I0IatayFNVdwN3d/dfAPaMvyRJUh8upZekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhrllxpLY+aXF2tSnIFLUqMMcElqlAEuSY2yBy5tUqvtpdt733qcgUtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY3yWijSGq3n2iNDX7dkpZ/v9VKmizNwSWqUAS5JjTLAJalR9sClns7tH7f8HpoeI2fgSV6d5LNJHkryWJJf6/ZfkuRokpPd7bbhy5UkndWnhfI/wDur6grgSuDaJFcB+4FjVbUbONZtS5ImZGSA16L/6jYv6v4VsBc41O0/BNw4RIGSpOX1OoiZ5IIkDwKngaNVdT+ws6pOAXS3OwarUpJ0nl4HMavqReDKJBcDdyX5zr5vkGQBWACYnZ1dS42SNogLfza3VZ1GWFX/AdwNXAs8m2QXQHd7eoXXHKyq+aqan5mZWV+1kqSv6XMWykw38ybJa4AfBD4PHAH2dU/bBxweqEZJ0jL6tFB2AYeSXMBi4N9RVZ9Ici9wR5JbgKeAmwasU5K0xMgAr6qHgTcvs/8FYM8QRUnqx4U/W5tL6SWpUQa4JDXKAJekRnkxK21Zm+Uc543qY2+W8WvtnIFLUqMMcElqlAEuSY2yBy41xnO/dZYzcElqlAEuSY0ywCWpUfbA1ZyteP6yfW8txxm4JDXKAJekRhngktQoe+AS091Xt38+vZyBS1KjDHBJapQBLkmNsgcujUHrfeZpPgYwzZyBS1KjDHBJapQBLkmNMsAlqVEexNTUW+0ButYPSGrrcAYuSY0ywCWpUQa4JDXKHrimhotRxsNjAO1wBi5JjTLAJalRBrgkNcoeuLYU+7tr1/cYg8ciJmfkDDzJ65P8TZITSR5Lcmu3/5IkR5Oc7G63DV+uJOmsPi2UM8AvVtWbgKuAn0tyObAfOFZVu4Fj3bYkaUJGBnhVnaqqf+jufwU4AVwK7AUOdU87BNw4UI2SpGWsqgeeZA54M3A/sLOqTsFiyCfZscJrFoAFgNnZ2XUVK7VmWnvuaxnXeq5JYy99eb3PQknyWuDjwC9U1Zf7vq6qDlbVfFXNz8zMrKVGSdIyegV4kotYDO8/qqo7u93PJtnVPb4LOD1MiZKk5fQ5CyXA7wMnquo3z3noCLCvu78PODz+8iRJK+nTA78auBl4JMmD3b4PAgeAO5LcAjwF3DRIhZpK9je1nGk9ZjCUkQFeVX8PZIWH94y3HElSXy6ll6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY3yeuAauyHO8fb8YOl8zsAlqVEGuCQ1ygCXpEYZ4JLUKA9iqmke3NRW5gxckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGeR64Ni3P8dYoW/3LsZ2BS1KjDHBJapQBLkmNsgcuSeuwkX14Z+CS1CgDXJIaZYBLUqPsgUuaOM/xHw9n4JLUKANckhplgEtSo+yBa2JW6nsO0Q+1xzq9/N3+v5Ez8CS3Jzmd5NFz9l2S5GiSk93ttmHLlCQt1aeF8hHg2iX79gPHqmo3cKzbliRN0MgAr6p7gC8u2b0XONTdPwTcON6yJEmjrLUHvrOqTgFU1akkO1Z6YpIFYAFgdnZ2jW8nqUXT2q+e5PGcVzL4WShVdbCq5qtqfmZmZui3k6QtY60B/mySXQDd7enxlSRJ6mOtAX4E2Nfd3wccHk85kqS++pxG+FHgXuCNSZ5OcgtwALgmyUngmm5bkjRBIw9iVtV7Vnhoz5hr0QZ6pYMvK12kfqt/oay00VxKL0mNMsAlqVEGuCQ1yotZaaQ+ve7NsrBBW9fQx2Q242fZGbgkNcoAl6RGGeCS1Ch74FqVzdgH1PRbz+dumtcrOAOXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRnge+QbbidRukSenz+e/znM1+3rgzcElqlAEuSY0ywCWpUfbAJWkFm/1YkjNwSWqUAS5JjTLAJalR9sDXYaX+2Gq/N3JcNWz2c1aljbbZe9qr5QxckhplgEtSowxwSWqUAS5JjZqqg5jTcEBvXF/eKmn6OQOXpEYZ4JLUKANckhrVTA98Ev3t1S7MWe3PkaRxWtcMPMm1Sb6Q5PEk+8dVlCRptDUHeJILgN8BrgMuB96T5PJxFSZJemXrmYG/FXi8qp6oqv8FPgbsHU9ZkqRRUlVre2HyLuDaqvrpbvtm4G1V9f4lz1sAFrrNNwJfALYDz6+16MZt5bHD1h7/Vh47OP71jP9bqmpm6c71HMTMMvvO+2tQVQeBgy97YXK8qubX8d7N2spjh609/q08dnD8Q4x/PS2Up4HXn7N9GfDM+sqRJPW1ngD/HLA7yRuSvAp4N3BkPGVJkkZZcwulqs4keT/wV8AFwO1V9VjPlx8c/ZSptZXHDlt7/Ft57OD4xz7+NR/ElCRtLJfSS1KjDHBJatRgAT5qmX0W/Vb3+MNJ3jJULRuhx/h/shv3w0k+k+SKjahzCH0vsZDke5K82K0pmBp9xp/k7UkeTPJYkr+ddI1D6vHZ/6Ykf57koW7879uIOoeQ5PYkp5M8usLj4829qhr7PxYPav4L8K3Aq4CHgMuXPOd64C9ZPJ/8KuD+IWrZiH89x/+9wLbu/nXTMv4+Yz/neZ8G/gJ410bXPeHf/cXAPwGz3faOja57wuP/IPAb3f0Z4IvAqza69jGN/weAtwCPrvD4WHNvqBl4n2X2e4E/qEX3ARcn2TVQPZM2cvxV9Zmq+lK3eR+L59FPg76XWPh54OPA6UkWNwF9xv8TwJ1V9RRAVU3Tf4M+4y/gdUkCvJbFAD8z2TKHUVX3sDielYw194YK8EuBfz9n++lu32qf06rVju0WFv8qT4ORY09yKfBjwIcnWNek9PndfzuwLcndSR5I8t6JVTe8PuP/beBNLC78ewS4tapemkx5G26suTfU9cD7LLPvtRS/Ub3HluQdLAb49w1a0eT0GfuHgA9U1YuLk7Cp0mf8FwLfDewBXgPcm+S+qvrnoYubgD7j/2HgQeCdwLcBR5P8XVV9eeDaNoOx5t5QAd5nmf00L8XvNbYk3wXcBlxXVS9MqLah9Rn7PPCxLry3A9cnOVNVfzaRCofV97P/fFV9FfhqknuAK4BpCPA+438fcKAWm8KPJ/lX4DuAz06mxA011twbqoXSZ5n9EeC93VHZq4D/rKpTA9UzaSPHn2QWuBO4eUpmXmeNHHtVvaGq5qpqDvhT4GenJLyh32f/MPD9SS5M8vXA24ATE65zKH3G/xSL//dBkp0sXqX0iYlWuXHGmnuDzMBrhWX2SX6me/zDLJ59cD3wOPDfLP5Vngo9x/8rwDcDv9vNRM/UFFyprefYp1af8VfViSSfAh4GXgJuq6plTztrTc/f/68DH0nyCIsthQ9U1VRcZjbJR4G3A9uTPA38KnARDJN7LqWXpEa5ElOSGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEb9H0RAo7TpILHxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([r['bleu-4'] for r in test_results], bins=100);\n",
    "np.mean([r['bleu-4'] for r in test_results]), np.median([r['bleu-4'] for r in test_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "522b4b65-9d47-4176-a087-353837f05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('val')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       device=args.device)\n",
    "batch_dict = next(batch_generator)\n",
    "\n",
    "model = model.eval().to(args.device)\n",
    "sampler = NMTSampler(vectorizer, model)\n",
    "sampler.apply_to_batch(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9d08d299-cbc8-46f1-a325-57c519d2b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for i in range(args.batch_size):\n",
    "    all_results.append(sampler.get_ith_item(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90fd2999-fa89-428e-b3d0-975a3ef10e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results = [x for x in all_results if x['bleu-4']>0.1]\n",
    "len(top_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2212f-a1cc-4e46-bb06-852da5bc5be9",
   "metadata": {},
   "source": [
    "<b>Helper functions</b>\n",
    "\n",
    "These are the helper functions for evaluating the seq2seq model's performance. Basically, the function get_all_sentences() returns the source text sequence, the target entity sequence and the predicted entity sequence that generated by our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "997f3af0-48cc-4a26-92f9-7bd08d16be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_sentence(vectorizer, batch_dict, index):\n",
    "    indices = batch_dict['x_source'][index].cpu().data.numpy()\n",
    "    vocab = vectorizer.source_vocab\n",
    "    return sentence_from_indices(indices, vocab)\n",
    "\n",
    "def get_true_sentence(vectorizer, batch_dict, index):\n",
    "    return sentence_from_indices(batch_dict['y_target'].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
    "    \n",
    "def get_sampled_sentence(vectorizer, batch_dict, index):\n",
    "    y_pred = model(x_source=batch_dict['x_source'], \n",
    "                   x_source_lengths=batch_dict['x_source_length'], \n",
    "                   target_sequence=batch_dict['x_target'])\n",
    "    return sentence_from_indices(torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
    "\n",
    "def get_all_sentences(vectorizer, batch_dict, index):\n",
    "    return {\"source\": get_source_sentence(vectorizer, batch_dict, index), \n",
    "            \"truth\": get_true_sentence(vectorizer, batch_dict, index), \n",
    "            \"sampled\": get_sampled_sentence(vectorizer, batch_dict, index)}\n",
    "    \n",
    "def sentence_from_indices(indices, vocab, strict=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            return \" \".join(out)\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304d49a-ac21-4a76-b705-bfabbc5e6c36",
   "metadata": {},
   "source": [
    "<b>Disagreements</b>\n",
    "\n",
    "The following codes are used to calculate the percentage of disagreements for 50 sentence sequences that are picked from test dataset. \n",
    "\n",
    "1. We make a list called \"index\" with length of batch size (64), and shuffle the list so that we can randomly pick up 50 instances from our test batch called \"batch_dict1\" that is assigned above\n",
    "2. Save all the related results (source, target, predic) to a list called \"fresults\"\n",
    "3. Function get_result() is used to get the correct predicted entities and incorrect predicted entities for each instance\n",
    "3. Function test_acc() is used to calculate the average accuracy of disagreements over 50 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e74f5c-b385-4225-baad-4b32722f186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the index so that we can randomly pick up 50 test data\n",
    "import random\n",
    "index = [i for i in range(args.batch_size)]\n",
    "random.shuffle(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "43d5fe62-7009-482b-a8c1-cea5b71d7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate 50 cases with source text, target entities and predicted entities\n",
    "fresults = [get_all_sentences(vectorizer, batch_dict1, i) for i in index[:50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109853fb-7d03-4f5f-ba22-51760d9c4fa6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f43dfb-2dab-4229-9c1a-4bb612f31a37",
   "metadata": {},
   "source": [
    "Due to each sentence contains a lot of entities with \"o\", which may not be a good way to evaluate the robustness of the model. So, we add a bool argument called \"rv\" in the funtion get_result() and test_acc() to determine if we want to compute the accuracy with 'o' or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a412c23-8eed-4946-a773-c72fda7a27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(index, rv = False): \n",
    "    \n",
    "    \"\"\"\n",
    "    rv determins if we want to calulate the accuracy without entities'o'\n",
    "    correct: Save the correct predicted entities\n",
    "    false: Save the incorrect predicted entities\n",
    "    \"\"\"\n",
    "    correct = []          \n",
    "    false = []\n",
    "    truth = fresults[index]['truth'].split()\n",
    "    sampled = fresults[index]['sampled'].split()\n",
    "    source = fresults[index]['source'].split()\n",
    "    \n",
    "    if len(truth) != len(source):\n",
    "        print(\"seq lenth error with truth length {} and source length {}!\".format(len(truth), len(source)))\n",
    "        return\n",
    "    \n",
    "    if rv:\n",
    "        truth = [result for result in truth if result != 'o']\n",
    "        sampled = [result1 for result1 in sampled if result1 != 'o']\n",
    "\n",
    "    for i in range(min(len(truth), len(sampled))):\n",
    "        if truth[i] == sampled[i]:\n",
    "            correct.append({\"sampled\": sampled[i], \"truth\": truth[i], \"source\": source[i]})\n",
    "        else:\n",
    "            false.append({\"sampled\": sampled[i], \"truth\": truth[i], \"source\": source[i]})\n",
    "    return correct, false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a245c04b-df5c-4240-b892-0ba61d8dd434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(rv = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    acc: Save the percentage of disagreements over 50 test instances\n",
    "    \"\"\"\n",
    "    acc= []\n",
    "    cor = []\n",
    "    fal = []\n",
    "    for i in range(len(fresults)):\n",
    "        correct, false = get_result(i, rv)\n",
    "        if len(correct) == 0 and len(false) == 0:\n",
    "            continue\n",
    "        cor.append(correct)\n",
    "        fal.append(false)\n",
    "        acc.append(len(correct)/(len(correct) + len(false)))\n",
    "    return np.average(np.array(acc)), cor, fal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "16098e8a-7c80-4fda-ada1-d0e1574feb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9198712476938635"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the disagreements on 50 test instances\n",
    "test_acc()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9be678c1-85e0-466e-93c9-367f7af85d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6992248062015504"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the disagreements on 50 test instances without 'o'\n",
    "test_acc(rv = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843f4c5-b040-493d-abd7-9750f3e64b7d",
   "metadata": {},
   "source": [
    "<b>Disagreements report</b>\n",
    "\n",
    "\n",
    "From the test result on 50 instances, the percentage of disagreements is around 8%, which means our seq2seq model has about 92% accuracy, shows outstanding performance for prediction. However, the percentage of disagreements is dropped around 30% if we evaluate without using entity 'o', which means the model has about 70% to predict the correct result for the entities except 'o'. Due to the our sequence dataset includes 90% of 'o' (we proved in data pre-process step), 70% accuracy is a decent result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8bd5f3-a771-404a-85e4-508865cf2cb8",
   "metadata": {},
   "source": [
    "<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe61a01-9c1c-45a2-98dc-d7a50d017d06",
   "metadata": {},
   "source": [
    "<b>Improvements and Future works</b>\n",
    "\n",
    "In this task, we use the bi-GRU as encoder, GRU as decoder and combine attention to train the seq2seq model. This models obtain a decent result on the test dataset. However, RNN related modes (RNN, GRU, LSTM) still facing the problem of short memory despite the significant improvment of using bidirectional strategy. Hence, the transformer method is proposed by Vaswani A and Shazeer N (2017) to address this problem. Transformer applys only the attention and access the token position using positional encoding. Positional encoding allows the model to catch up earlier text feature, thus improve the model accuracy when dealing with a long sequence. Moreover, this training datset includes 90% entity 'o'. In order to tackle this unbalance dataset, we can apply the Data Augmentatio technology. For example, in the paper \"Learning data manipulation for augmentation and weighting\". Hu Z and Tan B (2019) introduce how to reweight the data example so that the model can learn less from the simple data such as 'o' in this case, and learn more from the other hard data. Applying the Data Augmentatio technology with Transformer could be a better way to improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0193dd-73e1-410c-bc0c-bbc459b8f64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
